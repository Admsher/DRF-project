from qa_generator_pdf import qa_generator_pdf
from qa_generator_url import qa_generator_url
from qa_generator_gen_ai import qa_generator_gen_ai
from langchain_groq import ChatGroq
from langchain_core.prompts import ChatPromptTemplate
from langchain.prompts import PromptTemplate
from dotenv import load_dotenv
import os
import uuid
import ast
import json

# Load environment variables from .env file
load_dotenv()

llamaparse_api_key = os.getenv('LLAMA_API_KEY')
groq_api_key = os.getenv("GROQ_API_KEY")

'''

The method no_of_questions, sets the number of questions to be generated from 3 
different sources as per the requirement of the assesor.

Options given to assessor
1. 'pdf' -> Generate Questions and Answers from uploaded PDF
2. 'url' -> Generate Questions and Answers from uploaded URL
3. 'gen_ai' -> Generate Questions and Answers from Generative AI

Total number of questions to be generated =40

Set the Flag as true if the corresponding feature is selected by the 
accessor

'''

pdf = False
url = True
gen_ai = True

options = [pdf, url, gen_ai]

# Count the number of selected options
number_of_options = sum(options)

# Assign question distribution based on the number of selected options
if number_of_options == 1:
    questions_pdf, questions_url, questions_gen_ai = (40 if option else 0 for option in options)
elif number_of_options == 2:
    questions_pdf, questions_url, questions_gen_ai = (20 if option else 0 for option in options)
else:
    questions_pdf, questions_url, questions_gen_ai = 13, 13, 14

# print(questions_pdf)
# print(questions_url)
# print(questions_gen_ai)

def number_of_questions(no_questions):
    
    number_of_questions=no_questions
  
    # Calculate the base number of questions per level
    base_number = number_of_questions // 4

    # Calculate the remainder
    remainder = number_of_questions % 4

    # Create the list of questions per level, distributing the remainder
    number_of_questions_levelwise = [base_number + 1 if i < remainder else base_number for i in range(4)]
    
    return number_of_questions_levelwise
    



# set the job profile here
job_profile="Data Scientist"


#To store the questions and answers generated by different sources in three
# different dictionaries

result_dict_pdf={}
result_dict_url={}
result_dict_gen_ai={}
result_final={}

def extract_and_convert_to_dict(input_string):
    # Find the position of the first '{' and the last '}'
    start = input_string.find('{')
    end = input_string.rfind('}')
    
    if start == -1 or end == -1 or start >= end:
        raise ValueError("The input string does not contain valid JSON-like content.")
    
    # Extract the substring between the first '{' and the last '}'
    json_like_string = input_string[start:end+1]
    
    # Convert the extracted string to a dictionary
    result_dict = ast.literal_eval(json_like_string)
    
    return result_dict

def merge_with_unique_keys(input_dict, result_dict):
    for key, value in input_dict.items():
        # Generate a unique key using UUID
        unique_key = str(uuid.uuid4())
        # Add the key-value pair to the result dictionary
        result_dict[unique_key] = value

def merge_and_save_dicts(dict1, dict2, dict3, output_filename):
    # Merging the dictionaries, filtering out empty ones
    result_final = {**dict1, **dict2, **dict3}
    
    # Check if the final dictionary is empty
    if not result_final:
        print("All input dictionaries are empty. Nothing to save.")
        return
    
    # Saving the merged dictionary to a JSON file
    with open(output_filename, "w") as json_file:
        json.dump(result_final, json_file, indent=4)
    
    print(f"Merged dictionary saved to {output_filename}")


# to generate questions from PDF if pdf flag is set True
if pdf:
    
    qg_obj = qa_generator_pdf()
    
    #Pass the path of PDF here
    parsed_data = qg_obj.load_or_parse_data(llamaparse_api_key,"data/Decision_tree.pdf")

    embed_model= qg_obj.create_vector_database(parsed_data)

    chat_model=qg_obj.chat_model(groq_api_key)

    retriever=qg_obj.vectorstore(embed_model)

    
    # Create the list of questions level-wise
    number_of_questions_levelwise = number_of_questions(questions_pdf)

    print(number_of_questions_levelwise)

    custom_prompt_template = """Use the following pieces of information to answer questions of the user.
    Context: {context}
    question: {question}
    Only return the helpful content and nothing else.
    """

    prompt=qg_obj.output_generator(custom_prompt_template)
        
            
    query_template = f"""
    Generate {questions_pdf} technical interview questions and answers suitable for a 
    candidate applying for the following role :

    Please generate the specified number of questions exactly.

     **Job Profile:**

    {job_profile}
     Difficulty Distribution:
     - Easy: {number_of_questions_levelwise[0]} questions
     - Medium: {number_of_questions_levelwise[1]}questions
     - Hard: {number_of_questions_levelwise[2]} questions
     - Very Hard: {number_of_questions_levelwise[3]}questions
     
    first tell me the number of questions you are asked to create 
    for each difficult level. stock to those numbers only. 
     
    Formulate interview questions based on the provided content only,
    the specified difficulty levels, the responsibilities mentioned in the job 
    profile, and the listed requirements.

    Ensure that the exact specified number of questions are generated for each difficulty 
    level only. Do not set the numbers of questions generated for each difficulty
    level by yourself.

    Do not use reference of any table, example or any diagram in the provided content as
    the interviewee will not be provided with any material.

    Do not add questions and answers by yourself other than the provided content.

    Strictly use the provided content only.Do not generate questions
    on your own.
     
    Return the output as a Python dictionary where keys are the integer serial 
    number of the questions and answers, and values are Python dictionaries containing the 
    question, answer, and difficulty level. 
    Do not return anything other than the dictionary.
    
    The structure should be:
     {{
      "1": {{
        "question": "Example question",
        "answer": "Example answer",
        "difficulty": "Easy"
      }},
     "2": {{
        "question": "Example question",
        "answer": "Example answer",
        "difficulty": "Medium"
      }},
    ...
     }}
    """


    response=qg_obj.output_generator(chat_model,retriever,prompt,query_template)


    # print(type(response))

    # print(response)

    final_result=extract_and_convert_to_dict(response) 

    print(final_result.keys())

    merge_with_unique_keys(final_result,result_dict_pdf)

    for key, value in result_dict_pdf.items():
         print(str(key) + " ")
         print(value)
         print("\n")

    print("\n\n\n\n\n\n\n\n")


''' 
#Generate questions from URL based on the given URL by the user

'''

if url:
    
    url="https://www.ibm.com/topics/machine-learning"

    qg_obj=qa_generator_url

    number_of_questions_levelwise = number_of_questions(questions_url)

    print(number_of_questions_levelwise)
    print(job_profile)

    prompt=ChatPromptTemplate.from_template ("""
    Generate {questions_url} technical interview questions and answers suitable for a 
    candidate applying for the following role :
                                             
    Please generate the specified number of questions exactly.

     **Job Profile:**

    {job_profile}
     Difficulty Distribution:
     - Easy: {easy} questions
     - Medium: {medium} questions
     - Hard: {hard} questions
     - Very Hard: {veryhard} questions
  
    Formulate interview questions based on the provided content {data} only,
    the specified difficulty levels, the responsibilities mentioned in the job 
    profile, and the listed requirements. 

                
    Do not use reference of any table, example, any diagram or any such information from the
    content that is irrevelant to the interviewee from the provided content

    Do not add questions and answers by yourself other than the provided content.

    Return the output as a Python dictionary where keys are the integer serial 
    number of the questions and answers, and values are Python dictionaries containing the 
    question and answer. 
    Do not return anything other then the dictionary. Do not add the tag of difficulty level
    
    Return the output as a Python dictionary where keys are the integer serial 
    number of the questions and answers, and values are Python dictionaries containing the 
    question, answer, and difficulty level. 
    Do not return anything other than the dictionary.
    
    The structure should be:
     {{
      "1": {{
        "question": "Example question",
        "answer": "Example answer",
        "difficulty": "Easy"
      }},
     "2": {{
        "question": "Example question",
        "answer": "Example answer",
        "difficulty": "Medium"
      }},
    ...
     }}
    """)

   

    qg_object=qa_generator_url(url,n_href=None,prompt_template=prompt)
    response=qg_object.generate_questions(questions_url,number_of_questions_levelwise)

    # print(response)
  
    final_result=extract_and_convert_to_dict(response) 

    print(final_result.keys())

    merge_with_unique_keys(final_result,result_dict_url)

    for key, value in result_dict_url.items():
            print(f"{key}: {value}")
            print("\n\n")


'''
Generate question using Gen_ai (an LLM ) based on the Job profile and 
requirements.

'''

if gen_ai:
      
      print(questions_gen_ai)
      qg_obj=qa_generator_gen_ai()

      number_of_questions_levelwise=number_of_questions(questions_gen_ai)

      print(number_of_questions_levelwise)

      custom_prompt = """
    
      Generate {number_of_questions} technical interview questions and answers suitable for a 
      candidate applying for the following role :

      Please generate the specified number of questions exactly.

     **Job Profile:**

    {job_profile}
     Difficulty Distribution:
     - Easy: {easy} questions
     - Medium: {medium}questions
     - Hard: {hard} questions
     - Very Hard: {very_hard}questions

    Formulate interview questions based on the specified difficulty levels, the responsibilities mentioned in the job 
    profile, and the listed requirements. Ensure that the exact specified number of questions are generated for each difficulty 
    level only. Do not set the numbers of questions generated for each difficvulty
    level by yourself.

    Return the output as a Python dictionary where keys are the integer serial 
    number of the questions and answers, and values are Python dictionaries containing the 
    question, answer, and difficulty level. The questions should be in sequence, starting from 
    the easy difficulty level to the very hard difficulty level.

    Do not return anything other than the dictionary.
    
    The structure should be:
     {{
      "1": {{
        "question": "Example question",
        "answer": "Example answer",
        "difficulty": "Easy"
      }},
     "2": {{
        "question": "Example question",
        "answer": "Example answer",
        "difficulty": "Medium"
      }},
    ...
     """
 
    
      prompt = PromptTemplate(template=custom_prompt,
                            input_variables=['number_of_questions', 'job_profile','easy','medium','hard','very_hard'])

      response=qg_obj.question_generator("Data Scientist",prompt,questions_gen_ai,number_of_questions_levelwise)
      
      #print(response)
 
      final_result=extract_and_convert_to_dict(response) 

      print(final_result.keys())

      merge_with_unique_keys(final_result,result_dict_gen_ai)

      for key, value in result_dict_gen_ai.items():
            print(f"{key}: {value}")
            print("\n\n")

    
#Finally merging all dictionaries and saving in JSON format.

merge_and_save_dicts(result_dict_pdf,result_dict_url,result_dict_gen_ai,"transcript.json")



