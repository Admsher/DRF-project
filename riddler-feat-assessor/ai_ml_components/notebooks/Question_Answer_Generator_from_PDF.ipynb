{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jwgp7Lk_3Qiz"
      },
      "source": [
        "# QUESTIONS AND ANSWER GENERATOR FROM PDF\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uRdvnDGcoFya",
        "outputId": "613a1c87-b763-4db2-9834-896352f99552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting requirements.txt\n"
          ]
        }
      ],
      "source": [
        "%%writefile requirements.txt\n",
        "\n",
        "langchain\n",
        "langchain-community\n",
        "llama-parse\n",
        "fastembed\n",
        "chromadb\n",
        "python-dotenv\n",
        "langchain-groq\n",
        "chainlit\n",
        "fastembed\n",
        "unstructured[md]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_9wCBHloF2D",
        "outputId": "df940251-84cf-42a4-cd21-d5c73c55fac0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 2)) (0.1.17)\n",
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.0.37)\n",
            "Requirement already satisfied: llama-parse in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 4)) (0.4.2)\n",
            "Requirement already satisfied: fastembed in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 5)) (0.2.7)\n",
            "Requirement already satisfied: chromadb in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 6)) (0.5.0)\n",
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: langchain-groq in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (0.1.3)\n",
            "Requirement already satisfied: chainlit in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (1.0.506)\n",
            "Requirement already satisfied: unstructured[md] in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 11)) (0.13.6)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (0.5.14)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (1.33)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.48 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (0.1.54)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain->-r requirements.txt (line 2)) (8.2.3)\n",
            "Requirement already satisfied: llama-index-core>=0.10.29 in /usr/local/lib/python3.10/dist-packages (from llama-parse->-r requirements.txt (line 4)) (0.10.34)\n",
            "Requirement already satisfied: huggingface-hub<0.21,>=0.20 in /usr/local/lib/python3.10/dist-packages (from fastembed->-r requirements.txt (line 5)) (0.20.3)\n",
            "Requirement already satisfied: loguru<0.8.0,>=0.7.2 in /usr/local/lib/python3.10/dist-packages (from fastembed->-r requirements.txt (line 5)) (0.7.2)\n",
            "Requirement already satisfied: onnx<2.0.0,>=1.15.0 in /usr/local/lib/python3.10/dist-packages (from fastembed->-r requirements.txt (line 5)) (1.16.0)\n",
            "Requirement already satisfied: onnxruntime<2.0.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from fastembed->-r requirements.txt (line 5)) (1.17.3)\n",
            "Requirement already satisfied: tokenizers<0.16,>=0.15 in /usr/local/lib/python3.10/dist-packages (from fastembed->-r requirements.txt (line 5)) (0.15.2)\n",
            "Requirement already satisfied: tqdm<5.0,>=4.66 in /usr/local/lib/python3.10/dist-packages (from fastembed->-r requirements.txt (line 5)) (4.66.2)\n",
            "Requirement already satisfied: build>=1.0.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (1.2.1)\n",
            "Requirement already satisfied: chroma-hnswlib==0.7.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (0.7.3)\n",
            "Requirement already satisfied: fastapi>=0.95.2 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (0.110.3)\n",
            "Requirement already satisfied: uvicorn[standard]>=0.18.3 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (0.25.0)\n",
            "Requirement already satisfied: posthog>=2.4.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (4.11.0)\n",
            "Requirement already satisfied: opentelemetry-api>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-grpc>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-fastapi>=0.41b0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-sdk>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (1.24.0)\n",
            "Requirement already satisfied: pypika>=0.48.9 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (0.48.9)\n",
            "Requirement already satisfied: overrides>=7.3.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (7.7.0)\n",
            "Requirement already satisfied: importlib-resources in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (6.4.0)\n",
            "Requirement already satisfied: grpcio>=1.58.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (1.63.0)\n",
            "Requirement already satisfied: bcrypt>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (4.1.3)\n",
            "Requirement already satisfied: typer>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (0.9.4)\n",
            "Requirement already satisfied: kubernetes>=28.1.0 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (29.0.0)\n",
            "Requirement already satisfied: mmh3>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (4.1.0)\n",
            "Requirement already satisfied: orjson>=3.9.12 in /usr/local/lib/python3.10/dist-packages (from chromadb->-r requirements.txt (line 6)) (3.10.3)\n",
            "Requirement already satisfied: groq<1,>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from langchain-groq->-r requirements.txt (line 8)) (0.5.0)\n",
            "Requirement already satisfied: aiofiles<24.0.0,>=23.1.0 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (23.2.1)\n",
            "Requirement already satisfied: asyncer<0.0.3,>=0.0.2 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (0.0.2)\n",
            "Requirement already satisfied: click<9.0.0,>=8.1.3 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (8.1.7)\n",
            "Requirement already satisfied: fastapi-socketio<0.0.11,>=0.0.10 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (0.0.10)\n",
            "Requirement already satisfied: filetype<2.0.0,>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: httpx>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (0.27.0)\n",
            "Requirement already satisfied: lazify<0.5.0,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (0.4.0)\n",
            "Requirement already satisfied: literalai==0.0.509 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (0.0.509)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (1.6.0)\n",
            "Requirement already satisfied: packaging<24.0,>=23.1 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (23.2)\n",
            "Requirement already satisfied: pyjwt<3.0.0,>=2.8.0 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (2.8.0)\n",
            "Requirement already satisfied: python-graphql-client<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (0.4.3)\n",
            "Requirement already satisfied: python-multipart<0.0.10,>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (0.0.9)\n",
            "Requirement already satisfied: starlette<0.38.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (0.37.2)\n",
            "Requirement already satisfied: syncer<3.0.0,>=2.0.3 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (2.0.3)\n",
            "Requirement already satisfied: tomli<3.0.0,>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (2.0.1)\n",
            "Requirement already satisfied: uptrace<2.0.0,>=1.22.0 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (1.24.0)\n",
            "Requirement already satisfied: watchfiles<0.21.0,>=0.20.0 in /usr/local/lib/python3.10/dist-packages (from chainlit->-r requirements.txt (line 9)) (0.20.0)\n",
            "Requirement already satisfied: chevron>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from literalai==0.0.509->chainlit->-r requirements.txt (line 9)) (0.14.0)\n",
            "Requirement already satisfied: chardet in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (5.2.0)\n",
            "Requirement already satisfied: python-magic in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (0.4.27)\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (4.9.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (3.8.1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (0.9.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (4.12.3)\n",
            "Requirement already satisfied: emoji in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (2.11.1)\n",
            "Requirement already satisfied: python-iso639 in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (2024.4.27)\n",
            "Requirement already satisfied: langdetect in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (1.0.9)\n",
            "Requirement already satisfied: rapidfuzz in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (3.9.0)\n",
            "Requirement already satisfied: backoff in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (2.2.1)\n",
            "Requirement already satisfied: unstructured-client in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (0.18.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (1.14.1)\n",
            "Requirement already satisfied: markdown in /usr/local/lib/python3.10/dist-packages (from unstructured[md]->-r requirements.txt (line 11)) (3.6)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain->-r requirements.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: anyio<4.0.0,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from asyncer<0.0.3,>=0.0.2->chainlit->-r requirements.txt (line 9)) (3.7.1)\n",
            "Requirement already satisfied: pyproject_hooks in /usr/local/lib/python3.10/dist-packages (from build>=1.0.3->chromadb->-r requirements.txt (line 6)) (1.1.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2)) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain->-r requirements.txt (line 2)) (0.9.0)\n",
            "Requirement already satisfied: python-socketio>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (5.11.2)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 8)) (1.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from groq<1,>=0.4.1->langchain-groq->-r requirements.txt (line 8)) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit->-r requirements.txt (line 9)) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit->-r requirements.txt (line 9)) (1.0.5)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.23.0->chainlit->-r requirements.txt (line 9)) (3.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.23.0->chainlit->-r requirements.txt (line 9)) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.21,>=0.20->fastembed->-r requirements.txt (line 5)) (3.14.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<0.21,>=0.20->fastembed->-r requirements.txt (line 5)) (2023.6.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain->-r requirements.txt (line 2)) (2.4)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (2.8.2)\n",
            "Requirement already satisfied: google-auth>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (2.27.0)\n",
            "Requirement already satisfied: websocket-client!=0.40.0,!=0.41.*,!=0.42.*,>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (1.8.0)\n",
            "Requirement already satisfied: requests-oauthlib in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: oauthlib>=3.2.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (3.2.2)\n",
            "Requirement already satisfied: urllib3>=1.24.2 in /usr/local/lib/python3.10/dist-packages (from kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (2.0.7)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (1.2.14)\n",
            "Requirement already satisfied: dirtyjson<2.0.0,>=1.0.8 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (1.0.8)\n",
            "Requirement already satisfied: llamaindex-py-client<0.2.0,>=0.1.18 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (0.1.19)\n",
            "Requirement already satisfied: networkx>=3.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (3.3)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (1.26.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (2.0.3)\n",
            "Requirement already satisfied: pillow>=9.0.0 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (9.4.0)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (0.6.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[md]->-r requirements.txt (line 11)) (1.4.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk->unstructured[md]->-r requirements.txt (line 11)) (2023.12.25)\n",
            "Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx<2.0.0,>=1.15.0->fastembed->-r requirements.txt (line 5)) (3.20.3)\n",
            "Requirement already satisfied: coloredlogs in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 5)) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 5)) (24.3.25)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 5)) (1.12)\n",
            "Requirement already satisfied: importlib-metadata<=7.0,>=6.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 6)) (7.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos~=1.52 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 6)) (1.63.0)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-common==1.24.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 6)) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-proto==1.24.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp-proto-grpc>=1.2.0->chromadb->-r requirements.txt (line 6)) (1.24.0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation-asgi==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-instrumentation==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (0.45b0)\n",
            "Requirement already satisfied: opentelemetry-util-http==0.45b0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (0.45b0)\n",
            "Requirement already satisfied: setuptools>=16.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (67.7.2)\n",
            "Requirement already satisfied: asgiref~=3.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-instrumentation-asgi==0.45b0->opentelemetry-instrumentation-fastapi>=0.41b0->chromadb->-r requirements.txt (line 6)) (3.8.1)\n",
            "Requirement already satisfied: monotonic>=1.5 in /usr/local/lib/python3.10/dist-packages (from posthog>=2.4.0->chromadb->-r requirements.txt (line 6)) (1.6)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 2)) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain->-r requirements.txt (line 2)) (2.18.2)\n",
            "Requirement already satisfied: websockets>=5.0 in /usr/local/lib/python3.10/dist-packages (from python-graphql-client<0.5.0,>=0.4.3->chainlit->-r requirements.txt (line 9)) (12.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain->-r requirements.txt (line 2)) (3.3.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain->-r requirements.txt (line 2)) (3.0.3)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp~=1.24 in /usr/local/lib/python3.10/dist-packages (from uptrace<2.0.0,>=1.22.0->chainlit->-r requirements.txt (line 9)) (1.24.0)\n",
            "Requirement already satisfied: httptools>=0.5.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 6)) (0.6.1)\n",
            "Requirement already satisfied: uvloop!=0.15.0,!=0.15.1,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn[standard]>=0.18.3->chromadb->-r requirements.txt (line 6)) (0.19.0)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->unstructured[md]->-r requirements.txt (line 11)) (2.5)\n",
            "Requirement already satisfied: dataclasses-json-speakeasy>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]->-r requirements.txt (line 11)) (0.5.11)\n",
            "Requirement already satisfied: jsonpath-python>=1.0.6 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]->-r requirements.txt (line 11)) (1.0.6)\n",
            "Requirement already satisfied: mypy-extensions>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from unstructured-client->unstructured[md]->-r requirements.txt (line 11)) (1.0.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0.0,>=3.4.0->asyncer<0.0.3,>=0.0.2->chainlit->-r requirements.txt (line 9)) (1.2.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (4.9)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata<=7.0,>=6.0->opentelemetry-api>=1.2.0->chromadb->-r requirements.txt (line 6)) (3.18.1)\n",
            "Requirement already satisfied: opentelemetry-exporter-otlp-proto-http==1.24.0 in /usr/local/lib/python3.10/dist-packages (from opentelemetry-exporter-otlp~=1.24->uptrace<2.0.0,>=1.22.0->chainlit->-r requirements.txt (line 9)) (1.24.0)\n",
            "Requirement already satisfied: bidict>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (0.23.1)\n",
            "Requirement already satisfied: python-engineio>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (4.9.0)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in /usr/local/lib/python3.10/dist-packages (from coloredlogs->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 5)) (10.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index-core>=0.10.29->llama-parse->-r requirements.txt (line 4)) (2024.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime<2.0.0,>=1.17.0->fastembed->-r requirements.txt (line 5)) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.0.1->kubernetes>=28.1.0->chromadb->-r requirements.txt (line 6)) (0.6.0)\n",
            "Requirement already satisfied: simple-websocket>=0.10.0 in /usr/local/lib/python3.10/dist-packages (from python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (1.0.0)\n",
            "Requirement already satisfied: wsproto in /usr/local/lib/python3.10/dist-packages (from simple-websocket>=0.10.0->python-engineio>=4.8.0->python-socketio>=4.6.0->fastapi-socketio<0.0.11,>=0.0.10->chainlit->-r requirements.txt (line 9)) (1.2.0)\n"
          ]
        }
      ],
      "source": [
        "! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tbru7vNzvjDp"
      },
      "outputs": [],
      "source": [
        "##### LLAMAPARSE #####\n",
        "from llama_parse import LlamaParse\n",
        "\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_community.embeddings.fastembed import FastEmbedEmbeddings\n",
        "from langchain_community.vectorstores import Chroma\n",
        "from langchain_community.document_loaders import DirectoryLoader\n",
        "from langchain_community.document_loaders import UnstructuredMarkdownLoader\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.chains import RetrievalQA\n",
        "#\n",
        "from groq import Groq\n",
        "from langchain_groq import ChatGroq\n",
        "#\n",
        "import joblib\n",
        "import os\n",
        "import nest_asyncio  # noqa: E402\n",
        "nest_asyncio.apply()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VOk14j4oVCz",
        "outputId": "1d73ee80-b4b8-4a77-f6d2-bc1e717c6082"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: python-dotenv in /usr/local/lib/python3.10/dist-packages (1.0.1)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "# Load variables from .env file\n",
        "load_dotenv('.env')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SWt1U-UzpCnB"
      },
      "outputs": [],
      "source": [
        "llamaparse_api_key = os.getenv('LLAMA_API_KEY')\n",
        "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zcXNi529NBE"
      },
      "outputs": [],
      "source": [
        "!mkdir data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qn4SoBxNvJi_"
      },
      "outputs": [],
      "source": [
        "\n",
        "def load_or_parse_data():\n",
        "    data_file = \"./data/parsed_data.pkl\"\n",
        "\n",
        "    if os.path.exists(data_file):\n",
        "        # Load the parsed data from the file\n",
        "        parsed_data = joblib.load(data_file)\n",
        "    else:\n",
        "        # Perform the parsing step and store the result in llama_parse_documents\n",
        "        parsingInstruction = \"\"\" It contains tables.\n",
        "        Try to be precise while generating the questions and answers. \"\"\"\n",
        "        parser = LlamaParse(api_key=llamaparse_api_key,\n",
        "                            result_type=\"markdown\",\n",
        "                            parsing_instruction=parsingInstruction,\n",
        "                            max_timeout=10000,)\n",
        "        llama_parse_documents = parser.load_data(\"./data/Decision_tree.pdf\")\n",
        "\n",
        "\n",
        "        # Save the parsed data to a file\n",
        "        print(\"Saving the parse results in .pkl format ..........\")\n",
        "        joblib.dump(llama_parse_documents, data_file)\n",
        "\n",
        "        # Set the parsed data to the variable\n",
        "        parsed_data = llama_parse_documents\n",
        "\n",
        "\n",
        "    print(parsed_data)\n",
        "    return parsed_data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C2mm2Y_-CKz7",
        "outputId": "486fd3a5-d116-458c-e725-be42e4f96655"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Started parsing the file under job_id 5e261940-313f-48ef-856c-f30e2302e456\n",
            "Saving the parse results in .pkl format ..........\n",
            "[Document(id_='83d70dfe-de2f-4020-b277-76a0f61ce44e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='# Decision Trees Lecture\\n\\n# Lecture 7: Decision Trees\\n\\n|Contents|\\n|---|\\n|1 Learning Goals|3|\\n|2 Examples of Decision Trees|3|\\n|3 Definition and Classifying an Example|7|\\n|3.1 What is a decision tree?|7|\\n|3.2 Classifying an example using a decision tree|7|\\n|4 The Decision Tree Learning Algorithm|8|\\n|4.1 Issues in learning a decision tree|8|\\n|4.2 Grow a full tree given an order of testing features|8|\\n|4.3 When do we stop?|11|\\n|4.4 Base case 2: no features left|11|\\n|4.5 Base case 3: no examples left|13|\\n|4.6 Pseudo-code for the decision tree learner algorithm|15|\\n|5 Determine the Order of Testing Features|16|\\n|5.1 Which feature should we test at each step?|16|\\n|5.2 Identifying the most important feature|16|\\n|5.3 Entropy of a distribution over two outcomes|17|\\n|5.4 Expected information gain of testing a feature|19|\\n|5.5 A full example|20|\\n|6 Real-Valued Features|26|\\n|6.1 Jeeves dataset with real-valued temperatures|26|\\n|6.2 Handling a discrete feature|27|\\n|6.3 Handling a real-valued feature|28|\\n|6.4 Choosing a split point for a real-valued feature|28|\\n|7 Over-fitting|31|\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\nTopic\\nPage\\n\\nCorrupted data in the Jeeves dataset\\n31\\n\\nDealing with over-fitting with pruning\\n33\\n\\n## Practice Problems\\n\\n© Alice Gao 2021 - v1.0 - Page 2 of 36\\n---\\n# Decision Trees Lecture\\n\\n# Lecture 7\\n\\n## Learning Goals\\n\\nLearning Objectives\\nDescribe pe components of a decision tree.\\nConstruct a decision tree given an order of testing pe features.\\nDetermine pe prediction accuracy of a decision tree on a test set.\\nCompute pe entropy of a probability distribution.\\nCompute pe expected information gain for selecting a feature.\\nTrace pe execution of and implement pe ID3 algoripm.\\n\\n## Examples of Decision Trees\\n\\nOur first machine learning algorithm will be decision trees. A decision tree is a very common algorithm that we humans use to make many different decisions. You may be using one without realizing it. Here are some examples of decision trees:\\n\\nDecision Tree Example: Which language should you learn?\\n\\nWHICH LANGUAGE\\nSHOULD YOU LEARN IN 2018?\\nUSEFUL\\nOR\\nCOOL\\nEASY\\nOR\\nHARD\\nHIPSTER\\nOR\\nPHONETICS\\nOR\\nGRAMMAR\\nMANDARIN\\nHOLA\\nSPANISH\\nJAPANESE\\nCULTURETRIPCOM\\nv1.0\\n---\\n# Pet Selection Quiz\\n\\n# Pet Selection Quiz\\n\\nQuestion\\nAnswer\\n\\nDo you want a pet to love and care for?\\nYES\\n\\nAre you likely to forget you have a pet?\\nNO\\n\\nDo you want a creature that returns your affection?\\nYES\\n\\nDo you want to train your pet to do things?\\nYES\\n\\nDo you have a large open field?\\nYES\\n---\\n# CS 486/686 Lecture 7\\n\\nQuestion\\nAnswer\\n\\nExample: Should you use emoji in a conversation?\\nShould I Use Emoji in a conversation?\\n\\nAre individuals under 20 years old?\\nYes\\n\\nAre individuals over 65 years old?\\nNo\\n\\nIs this work-related?\\nNo\\n\\nAre individuals over 40 years old geeky?\\nNo\\n\\nWill you like being interrupted?\\nNo\\n\\nAre you trying to avoid making people feel alienated?\\nYes\\n\\nAre you being the smartest person in the room?\\nNo\\n\\nDo not use\\nIdiot\\n---\\n# Lecture 7\\n\\n# Example Data for Tennis Prediction\\n\\nTraining Set\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n\\n14\\nRain\\nMild\\nHigh\\nStrong\\nNo\\n\\nTest Set\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\nMild\\nHigh\\nStrong\\nNo\\n\\n2\\nRain\\nHot\\nNormal\\nStrong\\nNo\\n\\n3\\nRain\\nCool\\nHigh\\nStrong\\nNo\\n\\n4\\nOvercast\\nHot\\nHigh\\nStrong\\nYes\\n\\n5\\nOvercast\\nCool\\nNormal\\nWeak\\nYes\\n\\n6\\nRain\\nHot\\nHigh\\nWeak\\nYes\\n\\n7\\nOvercast\\nMild\\nNormal\\nWeak\\nYes\\n\\n8\\nOvercast\\nCool\\nHigh\\nWeak\\nYes\\n\\n9\\nRain\\nCool\\nHigh\\nWeak\\nYes\\n\\n10\\nRain\\nMild\\nNormal\\nStrong\\nNo\\n\\n11\\nOvercast\\nMild\\nHigh\\nWeak\\nYes\\n\\n12\\nSunny\\nMild\\nNormal\\nWeak\\nYes\\n\\n13\\nSunny\\nCool\\nHigh\\nStrong\\nNo\\n\\n14\\nSunny\\nCool\\nHigh\\nWeak\\nNo\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\n3.1 What is a decision tree?\\n\\nA decision tree is a simple model for supervised classification. It is used for classifying a single discrete target feature. Each internal node performs a Boolean test on an input feature. The edges are labeled wip pe values of pat input feature. Each leaf node specifies a value for pe target feature.\\n\\n3.2 Classifying an example using a decision tree\\n\\nClassifying an example using a decision tree is very intuitive. We traverse down pe tree, evaluating each test and following pe corresponding edge. When a leaf is reached, we return pe classification on pat leaf.\\n\\n### Example:\\n\\nHere is an example of using the emoji decision tree. Assume:\\n\\n- I am 30 years old.\\n- This is work related.\\n- I am an accountant.\\n- I am not trying to get fired.\\n\\nFollowing the tree, we answer no (not under 20 years old), no (not over 65 years old), yes (work related), no (not working in tech), and no (not trying to get fired). The leaf we reach is a thumb down, meaning we should not use emoji.\\n\\n### Problem:\\n\\nIf we convert a decision tree to a program, what does it look like?\\n\\n### Solution:\\n\\nA decision tree corresponds to a program with a big nested if-then-else structure.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 7 of 36\\n---\\n# Decision Tree Learning Algorithm\\n\\n# CS 486/686 - Lecture 7\\n\\n## 4. The Decision Tree Learning Algorithm\\n\\n### 4.1 Issues in learning a decision tree\\n\\nHow can we build a decision tree given a data set? First, we need to decide on an order of testing the input features. Next, given an order of testing the input features, we can build a decision tree by splitting the examples whenever we test an input feature.\\n\\nLet’s take a look at the Jeeves training set again. Each row is an example. There are 14 examples. For each example, we have five feature values: day, outlook, temperature, humidity, and wind. In fact, Day is not a useful feature since it’s different for every example. So, we will focus on the other four input features. We have one target feature or label, which is whether Bertie decided to play tennis or not.\\n\\nThe decision tree is a powerful and flexible model. Given a data set, we can generate many different decision trees. Therefore, there are a few questions we need to think about when deciding which tree we should build.\\n\\nFirst, different orders of testing the input features will lead to different decision trees. So, which order should we use? The number of possible orders is quite large, so it is challenging to find the optimal order in the search space. Given this, we will use a greedy or myopic approach. Instead of finding the optimal order of testing the features, we will make the myopic best choice at each step.\\n\\nYou might be wondering, what is the difference between making the optimal choice versus making the myopic best choice at each step? The main difference is that the optimal strategy considers the future, whereas the myopic strategy only cares about the current step. To generate an optimal tree, at each step, we need to think about how our feature choice at this step might affect our choices in the future. On the contrary, the myopic strategy does not think about the future at all and only cares about finding the best feature to test at the current step.\\n\\nNow, suppose that we have chosen an order of testing the features using the myopic strategy. We have another choice. Should we grow a full tree or should we stop growing the tree earlier? Recall that I discussed over-fitting previously. The full tree may over-fit the training data, so a smaller tree might be better since it might generalize better to unseen test data.\\n\\nTo answer this question, we need a bias or an assumption that we make about which tree we prefer. One possible assumption could be based on Occam’s razor principle, which says that the simplest model or hypothesis is probably the best. Based on Occam’s razor, we would prefer a tree that is smaller than the full tree. This still leaves lots of options for us. For example, we can grow the tree until a certain depth, or we can grow the tree until it has a certain number of nodes.\\n\\n### 4.2 Grow a full tree given an order of testing features\\n\\nLet’s go through an example of constructing the full tree using the Jeeves training set. I’ve given you an order of testing the input features below.\\n\\nOrder of Testing Features\\n1. Outlook\\n2. Temperature\\n3. Humidity\\n4. Wind\\n\\n© Alice Gao 2021 - v1.0 - Page 8 of 36\\n---\\n# Decision Tree Construction\\n\\n# Decision Tree Construction\\n\\nOrder of Testing Features\\n1. Test Outlook\\n2. For Outlook = Sunny, test Temp\\n3. For Outlook = Rain, test Wind\\n4. For oper branches, test Humidity before testing Wind\\n\\n## Problem:\\n\\nConstruct a (full) decision tree for the Jeeves data set using the given order of testing features.\\n\\n### Solution:\\n\\nProcess to generate the decision tree:\\n\\n1. We have 9 positive and 5 negative examples.\\n2. Since the examples are not in the same class, we need to choose a feature to test.\\n3. Based on the order provided, we start by testing Outlook.\\n4. Outlook has three values: Sunny, Overcast, and Rain. We split the examples into three branches accordingly.\\n\\nThe sets after splitting based on Outlook:\\n\\nExample\\nOutlook\\n\\n1\\nSunny\\n\\n2\\nOvercast\\n\\n3\\nRain\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 9 of 36\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\nBranch\\nExamples\\nDecision\\n\\nMiddle\\nAll positive\\nCreate leaf node with label Yes\\n\\nLeft\\n2 positive, 3 negative\\nTest feature Temp\\n\\nWe will repeat this process at every node. First, check if all the examples are in the same class. If they are, create a leaf node with the class label and stop. Otherwise, choose the next feature to test and split the examples based on the chosen feature.\\n\\n© Alice Gao 2021 - v1.0 - Page 10 of 36\\n---\\n# Decision Tree Lecture\\n\\n# Decision Tree Lecture\\n\\n|Temp|Yes|Wind|\\n|---|---|---|\\n|No|Humidity|Yes|Wind|\\n| |No|Yes|Yes|No|\\n\\n## When do we stop?\\n\\nThere are three possible stopping criteria for the decision tree algorithm. For the example in the previous section, we encountered the first case only: when all of the examples belong to the same class. In this case, we make the decision of that class and then we’re done.\\n\\n## Base case 2: no features left\\n\\nLet’s look at the second case: what should we do if there are no more features to test?\\n\\nProblem: I took our training set and added a few examples. It now has 17 instead of 14 examples. For this modified training set, let’s construct one branch of the decision tree where Outlook is Sunny, Temperature is Mild, and Humidity is High.\\n---\\n# CS 486/686 Lecture 7\\n\\n# CS 486/686 Lecture 7\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n\\n16\\nSunny\\nMild\\nHigh\\nWeak\\nYes\\n\\n17\\nSunny\\nMild\\nHigh\\nStrong\\nYes\\n\\nSolution: After testing Humidity is High, the next step is to test the Wind feature. When Wind is Strong, the decision is Yes. When Wind is Weak, there are mixed results, so no decision can be made. In such cases, when all features have been tested, and no clear decision can be reached, one option is to predict the majority class or make a randomized decision.\\n\\nWhen we run out of features to test, and the data set is noisy with conflicting labels for the same input values, we can consider predicting the majority class or making a randomized decision based on the distribution of outcomes.\\n\\nFor the given example, the majority decision when Wind is Weak is No.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 12 of 36\\n---\\n# CS 486/686 Lecture 7\\n\\n## Decision Tree Branch\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n3\\nOvercast\\nHot\\nHigh\\nWeak\\nYes\\n\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n\\n12\\nOvercast\\nMild\\nHigh\\nStrong\\nYes\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\nTemperature\\nOutlook\\nWind\\nHumidity\\nDecision\\n\\nHot\\nSunny\\nWeak\\nHigh\\nNo\\n\\nHot\\nOvercast\\nWeak\\nHigh\\nYes\\n\\nHot\\nRain\\nWeak\\nHigh\\nNo\\n\\nWhen encountering the case where Outlook is Rain and there are no examples left, we need to handle it by considering examples from the parent node.\\n\\nWe can use the examples at the parent node, which are likely to be mixed, to make a decision. This decision can be based on either the majority decision or a random draw from a probability distribution.\\n\\nThis approach helps in situations where certain combinations of feature values are not observed in the dataset, allowing us to still make informed decisions.\\n---\\n# Decision Tree Learner Algorithm\\n\\n## Pseudo-code for the decision tree learner algorithm\\n\\nAlgoripm 1 Decision Tree Learner (examples, features)\\n\\n1. if all examples are in pe same class pen\\n2. return pe class label.\\n3. else if no features left pen\\n4. return pe majority decision.\\n5. else if no examples left pen\\n6. return pe majority decision at pe parent node.\\n7. else\\n8. choose a feature f .\\n9. for each value v of feature f do\\n10. build edge wip label v.\\n11. build sub-tree using examples where pe value of f is v.\\n\\nHere is the pseudocode for the algorithm. Since a tree is recursive, we will naturally use a recursive algorithm to build it.\\n\\nThe algorithm starts with three base cases:\\n\\n1. If all the examples are in the same class, we will return the class label.\\n2. If there are no features left, we have noisy data. We can either return the majority decision or make a decision probabilistically.\\n3. If there are no examples left, then some combination of input features is absent in the training set. We can use the examples at the parent node to make a decision. If the examples are not in the same class, we can either return the majority decision or make a decision probabilistically.\\n\\nNext, we have the recursive part. Suppose that we have a pre-specified order of testing the input features. At each step, we will split up the examples based on the chosen feature’s values. We will label the edges with the feature’s value. Each subtree only has examples where the value of the feature corresponds to the value on the edge.\\n\\nThere’s one crucial step left. So far, we have assumed that a pre-defined order of testing the input features. Where does this order come from? In practice, we have to choose this order ourselves.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 15 of 36\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\nQuestion\\nAnswer\\n\\n5.1 Which feature should we test at each step?\\nWe should choose a feature that makes the biggest difference to the classification or helps in making a decision quickly. The approach is to minimize the number of features to test by learning a small and shallow tree, using a greedy and myopic approach.\\n\\n5.2 How do we identify the most important feature?\\nTo identify the most important feature, we calculate the reduction in uncertainty by subtracting the uncertainty in examples after testing the feature from the uncertainty before testing the feature. This information content is measured using entropy from information theory, which is calculated based on the probability distribution over outcomes.\\n---\\n# Entropy Calculation Questions\\n\\n# Entropy Calculation Questions\\n\\nProblem\\nOptions\\n\\nWhat is the entropy of the distribution (0.5, 0.5)?\\n- (A) 0.2\\n- (B) 0.4\\n- (C) 0.6\\n- (D) 0.8\\n- (E) 1\\n\\nSolution:\\nThe correct answer is (E).\\n\\nPerforming the calculation, we have:\\n-(0.5 * log2(0.5)) * 2 = 1\\n\\nThe entropy is 1 bit.\\n\\nYou might be wondering, is one bit of entropy a lot or very little? You will get a better idea of this after question 2. For now, believe me when I say that there is a lot of uncertainty in this binary distribution.\\n\\nThis should make intuitive sense. This distribution is uniform. A uniform distribution has a lot of uncertainty since every outcome is equally likely to become true.\\n\\nWhat is the entropy of the distribution (0.01, 0.99)?\\n- (A) 0.02\\n- (B) 0.04\\n- (C) 0.06\\n- (D) 0.08\\n\\nWe have a very skewed distribution. Almost all the probability is on the second outcome.\\n---\\n# Entropy Questions\\n\\n# Entropy Questions\\n\\nProblem\\nSolution\\n\\n1. What is the maximum entropy of the distribution (p, 1 - p) where 0 ≤ p ≤ 1?\\nFor any binary distribution, its entropy achieves its maximum value of one when the distribution is uniform.\\n\\n2. What is the minimum entropy of the distribution (p, 1 - p) where 0 ≤ p ≤ 1?\\nThe entropy achieves its minimum value of zero when the distribution is a point mass — one outcome has a probability of 1.\\n\\n3. Plot the entropy of the distribution (p, 1 - p) with respect to p.\\nAs p increases from 0 to 1, the entropy increases first, reaches the maximum value when p is 0.5, and then decreases after that.\\n---\\n# Lecture 7 Summary\\n\\n# CS 486/686 - Lecture 7 Summary\\n\\n## Practice Question\\n\\nWhat are the maximum and minimum entropy for a distribution with three outcomes?\\n\\n## Expected Information Gain of Testing a Feature\\n\\nHow can we quantify the information content of a feature?\\n\\nFeature Value\\nPositive Examples\\nNegative Examples\\n\\nv1\\nP1\\nN1\\n\\nv2\\nP2\\nN2\\n\\n...\\n...\\n...\\n\\nvk\\nPk\\nNk\\n\\nExpected Information Gain Formula:\\n\\nIbefore = I(p, n) / (p + n)\\n\\nAfter testing the feature, we have k distributions. How do we calculate the entropy of k distributions?\\n---\\n# Decision Tree Example\\n\\n# Decision Tree Example\\n\\nHere, we will work through generating a complete decision tree based on the rules introduced in this section. We can start with the following questions:\\n\\n## Problem:\\n\\nWhat is the entropy of the examples before we select a feature for the root node of the tree?\\n\\nOptions\\nEntropy Value\\n\\n(A)\\n0.54\\n\\n(B)\\n0.64\\n\\n(C)\\n0.74\\n\\n(D)\\n0.84\\n\\n(E)\\n0.94\\n\\n## Solution:\\n\\nThere are 14 examples: 9 positive, 5 negative. Applying the formula gives:\\n\\nHbefore = - (9 log2(9) + 5 log2(5)) / 14\\n\\n= - (9 * (-0.637) + 5 * (-1.485)) / 14\\n\\n= -(-0.939)\\n\\n≈ 0.94\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 20 of 36\\n---\\n# Questions\\n\\n|Problem|Options|\\n|---|---|\\n|What is the expected information gain if we select Outlook as the root node of the tree?|- (A) 0.237\\n- (B) 0.247\\n- (C) 0.257\\n- (D) 0.267\\n- (E) 0.277\\n|\\n|What is the expected information gain if we select Humidity as the root node of the tree?|- (A) 0.151\\n- (B) 0.251\\n|\\n---\\n# Lecture 7\\n\\n## Question:\\n\\nWhat is pe expected information gain for testing Humidity?\\n\\n### Options:\\n\\n(A) 0.151\\n(B) 0.251\\n(C) 0.351\\n(D) 0.451\\n(E) 0.551\\n\\n### Solution:\\n\\nGain(Humidity) = 0.94 - 7 * I(6,1) + 7 * I(3,4)\\n= 0.94 - 7(0.592) + 7(0.985)\\n= 0.94 - 0.78914\\n= 0.151\\n\\nThe correct answer is (A).\\n\\n## Additional Information:\\n\\nComparing Outlook and Humidity, the expected information gain of testing Outlook first is greater than that of testing Humidity first. When comparing features to test at a node, we could simply ignore the entropy before testing and select the feature with the lowest post-testing entropy.\\n\\n### Example:\\n\\nFor the root node, the expected information gain for testing different features is as follows:\\n\\nGain(Outlook) = 0.247\\nGain(Humidity) = 0.151\\nGain(Temp) = 0.029\\nGain(Wind) = 0.048\\n\\nWe pick Outlook since it has the greatest expected information gain.\\n\\n© Alice Gao 2021 - v1.0 - Page 22 of 36\\n---\\n# Lecture 7\\n\\n# Decision Tree Analysis\\n\\n|Case 1|Outlook = Sunny|\\n|---|---|\\n|Hot|+ : 9, 11|- : 1, 2, 8|\\n| |Mild|+ : 11|- : 8|\\n| |Cool|+ : 9|-|\\n\\nGain(Temp) = 0.57\\n\\n|Humidity|\\n|---|\\n|High|+ :|- : 1, 2, 8|\\n|Normal|+ : 9, 11|-|\\n\\nGain(Humidity) = 0.97\\n\\n|Wind|\\n|---|\\n|Weak|+ : 9|- : 11|\\n|Strong|+ : 1, 8|- : 2|\\n\\nGain(Wind) = 0.019\\n\\nWe pick Humidity since it has the greatest expected information gain. This makes sense since the positive and negative examples are completely separated after testing Humidity.\\n\\n|Case 2|Outlook = Overcast|\\n|---|---|\\n| |+ : 3, 7, 12, 13|-|\\n---\\n# Lecture 7\\n\\n# Decision Tree Analysis\\n\\nCase\\nOutlook\\nTemp\\nHumidity\\nWind\\n\\n1\\nSunny\\nHot\\nHigh\\nWeak\\n\\n2\\nSunny\\nHot\\nHigh\\nStrong\\n\\n3\\nRain\\nMild\\nHigh\\nWeak\\n\\n4\\nRain\\nCool\\nNormal\\nWeak\\n\\n5\\nRain\\nMild\\nNormal\\nWeak\\n\\n6\\nSunny\\nMild\\nHigh\\nWeak\\n\\n7\\nSunny\\nCool\\nNormal\\nStrong\\n\\n8\\nRain\\nMild\\nHigh\\nStrong\\n\\n9\\nSunny\\nMild\\nNormal\\nWeak\\n\\n10\\nRain\\nMild\\nNormal\\nWeak\\n\\nWe pick Wind since it has the greatest expected information gain. This makes sense since the positive and negative examples are completely separated after testing Wind.\\n\\nThe final decision tree is drawn below:\\n\\n© Alice Gao 2021 | v1.0 | Page 24 of 36\\n---\\n# Decision Tree - Outlook, Humidity, Wind\\n\\n# Decision Tree - Weather Conditions\\n\\nOutlook\\nHumidity\\nWind\\n\\n1\\nSunny\\nHigh\\nWeak\\n\\n2\\nSunny\\nHigh\\nStrong\\n\\n3\\nOvercast\\n\\n4\\nRain\\nNormal\\nWeak\\n\\n5\\nRain\\nNormal\\n\\n6\\nRain\\n\\nStrong\\n\\n7\\nOvercast\\n\\n8\\nSunny\\nHigh\\n\\n9\\nSunny\\nNormal\\nWeak\\n\\n10\\nRain\\nNormal\\nWeak\\n\\n11\\nSunny\\nNormal\\nWeak\\n\\n12\\nOvercast\\n\\n13\\nOvercast\\n\\n14\\nRain\\n\\nStrong\\n---\\n# Lecture 7 - Real-Valued Features\\n\\n# CS 486/686 - Lecture 7\\n\\n## Real-Valued Features\\n\\n### Jeeves dataset with real-valued temperatures\\n\\nSo far, the decision tree learner algorithm only works when all of the features have discrete values. In the real world, we are going to encounter a lot of data sets where many features have continuous values, or they’re real-valued. Let’s see how decision trees can handle them.\\n\\n#### Example: A more realistic Jeeves dataset with real-valued temperatures\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\n29.4\\nHigh\\nWeak\\nNo\\n\\n2\\nSunny\\n26.6\\nHigh\\nStrong\\nNo\\n\\n3\\nOvercast\\n28.3\\nHigh\\nWeak\\nYes\\n\\n4\\nRain\\n21.1\\nHigh\\nWeak\\nYes\\n\\n5\\nRain\\n20.0\\nNormal\\nWeak\\nYes\\n\\n6\\nRain\\n18.3\\nNormal\\nStrong\\nNo\\n\\n7\\nOvercast\\n17.7\\nNormal\\nStrong\\nYes\\n\\n8\\nSunny\\n22.2\\nHigh\\nWeak\\nNo\\n\\n9\\nSunny\\n20.6\\nNormal\\nWeak\\nYes\\n\\n10\\nRain\\n23.9\\nNormal\\nWeak\\nYes\\n\\n11\\nSunny\\n23.9\\nNormal\\nStrong\\nYes\\n\\n12\\nOvercast\\n22.2\\nHigh\\nStrong\\nYes\\n\\n13\\nOvercast\\n27.2\\nNormal\\nWeak\\nYes\\n\\n14\\nRain\\n21.7\\nHigh\\nStrong\\nNo\\n\\nInstead of having the temperature being a discrete feature, having three values: Mild, Hot, and Cool, we will use actual numbers for Temperature.\\n\\nFor convenience, we will reorder the data set based on the value of the Temperature.\\n\\n#### Example: Jeeves dataset ordered by temperatures\\n\\n© Alice Gao 2021 - v1.0 - Page 26 of 36\\n---\\n# Lecture 7\\n\\n## Day Outlook Temp Humidity Wind Tennis?\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n7\\nOvercast\\n17.7\\nNormal\\nStrong\\nYes\\n\\n6\\nRain\\n18.3\\nNormal\\nStrong\\nNo\\n\\n5\\nRain\\n20.0\\nNormal\\nWeak\\nYes\\n\\n9\\nSunny\\n20.6\\nNormal\\nWeak\\nYes\\n\\n4\\nRain\\n21.1\\nHigh\\nWeak\\nYes\\n\\n14\\nRain\\n21.7\\nHigh\\nStrong\\nNo\\n\\n8\\nSunny\\n22.2\\nHigh\\nWeak\\nNo\\n\\n12\\nOvercast\\n22.2\\nHigh\\nStrong\\nYes\\n\\n10\\nRain\\n23.9\\nNormal\\nWeak\\nYes\\n\\n11\\nSunny\\n23.9\\nNormal\\nStrong\\nYes\\n\\n2\\nSunny\\n26.6\\nHigh\\nStrong\\nNo\\n\\n13\\nOvercast\\n27.2\\nNormal\\nWeak\\nYes\\n\\n3\\nOvercast\\n28.3\\nHigh\\nWeak\\nYes\\n\\n1\\nSunny\\n29.4\\nHigh\\nWeak\\nNo\\n\\n## Handling a discrete feature\\n\\nBefore seeing how we can handle real-valued features, let’s review how we can handle a discrete feature. We considered two options:\\n\\n- Allow multi-way splits:\\n- The tree becomes more complex than just if-then-else.\\n- The tree tends to be shallower.\\n- The expected information gain metric prefers a variable with a larger domain, because when a variable has a larger domain we can split the data points into more sets, and there’s a higher chance to reduce entropy.\\n- Restrict to binary splits:\\n- The tree is simpler and more compact.\\n- The tree tends to be deeper.\\n\\nExample: As an extreme example, pretend that Day is an additional input feature in the Jeeves dataset, then the expected information gain for splitting on day must be the largest. Since we have one example for each day, and we can make a deterministic decision right away after splitting on day. However, it clearly does not make sense to use day as a feature, as the resulting tree does not generalize to any other data sets.\\n\\n&copy; Alice Gao 2021 | v1.0 | Page 27 of 36\\n---\\n# Lecture 7 Summary\\n\\n# CS 486/686 - Lecture 7 Summary\\n\\n## Handling a real-valued feature\\n\\nMethods for handling a real-valued feature\\nConsiderations\\n\\nDiscretize the feature\\nEasy to implement but may lose valuable information\\n\\nAllow multi-way splits\\nImpractical due to unbounded feature domain\\n\\nRestrict to binary splits\\nChoose split points dynamically; may lead to deeper trees\\n\\n## Choosing a split point for a real-valued feature\\n\\nA na&iuml;ve way to choose a split point:\\n\\n1. Sort instances by the real-valued feature\\n2. Consider midpoints of consecutive values as possible split points\\n3. Calculate expected information gain for each split point\\n4. Pick the split point with the greatest expected information gain\\n\\nSmarter approach:\\n\\n1. Sort instances by the real-valued feature\\n2. Identify possible split points as midway between different adjacent values\\n3. Consider (X + Y)/2 as a split point if labels differ between X and Y\\n\\nExample: With the modified Jeeves data set, there are 11 possible split points using the na&iuml;ve method.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 28 of 36\\n---\\n# Information Gain and Split Points\\n\\n# Information Gain and Split Points\\n\\nProblem\\nQuestion\\n\\nFor the Jeeves training set, is the midpoint between 20.0 and 20.6 a possible split point?\\n(A) Yes (B) No\\n\\nSolution\\nThis is not a possible split point: L= {Yes} and L= {Yes}. 20.0 20.6 The correct answer is (B).\\n\\nProblem\\nFor the Jeeves training set, is the midpoint between 21.1 and 21.7 a possible split point?\\n\\nQuestion\\n(A) Yes (B) No\\n\\nSolution\\nThis is a possible split point: L= {Yes} and L= {No}. 21.1 21.7 The correct answer is (A).\\n\\nProblem\\nFor the Jeeves training set, is the midpoint between 21.7 and 22.2 a possible split point?\\n\\nQuestion\\n(A) Yes (B) No\\n\\nSolution\\nThe correct answer is (B).\\n\\n©c Alice Gao 2021 v1.0 Page 29 of 36\\n---\\ntable {\\nwidth: 100%;\\nborder-collapse: collapse;\\n}\\ntable, th, td {\\nborder: 1px solid black;\\n}\\nth, td {\\npadding: 10px;\\ntext-align: left;\\n}\\n\\n## Question:\\n\\nQuestion 21:\\nWhat is a possible split point according to the solution provided?\\n\\n## Answer:\\n\\nAnswer:\\nA possible split point is L = {No} and L = {No, Yes}.\\n\\n## Explanation:\\n\\nExplanation:\\nIntuitively, the procedure considers local changes at each midway point. If the target feature doesn’t change locally, that point probably isn’t a valuable split point.\\n---\\n# Lecture 7: Over-fitting\\n\\n# CS 486/686 - Lecture 7\\n\\n## 7. Over-fitting\\n\\n### 7.1 Corrupted data in the Jeeves dataset\\n\\nOver-fitting is a common problem when learning a decision tree. Decision trees have several advantages in supervised machine learning, such as simplicity, ease of understanding, and interpretability.\\n\\nWhile decision trees are good for explaining models to humans, neural networks can be complex and hard to interpret. Decision trees can also work well with small datasets, unlike neural networks which are prone to over-fitting with limited data.\\n\\nDespite the benefits of decision trees, over-fitting remains a challenge during construction.\\n\\n#### Example: The Jeeves dataset\\n\\n|Day|Outlook|Temp|Humidity|Wind|Tennis?|\\n|---|---|---|---|---|---|\\n|1|Sunny|Hot|High|Weak|No|\\n|2|Sunny|Hot|High|Strong|No|\\n|3|Overcast|Hot|High|Weak|Yes|\\n|4|Rain|Mild|High|Weak|Yes|\\n|5|Rain|Cool|Normal|Weak|Yes|\\n|6|Rain|Cool|Normal|Strong|No|\\n|7|Overcast|Cool|Normal|Strong|Yes|\\n|8|Sunny|Mild|High|Weak|No|\\n|9|Sunny|Cool|Normal|Weak|Yes|\\n|10|Rain|Mild|Normal|Weak|Yes|\\n|11|Sunny|Mild|Normal|Strong|Yes|\\n|12|Overcast|Mild|High|Strong|Yes|\\n|13|Overcast|Hot|Normal|Weak|Yes|\\n|14|Rain|Mild|High|Strong|No|\\n\\nDecision tree generated by the learner algorithm:\\n\\n© Alice Gao 2021 - v1.0 - Page 31 of 36\\n---\\n# Lecture 7 - Decision Tree\\n\\n# Decision Tree Analysis\\n\\nTest error is 0 out of 14.\\n\\nExample: Suppose that you sent the training set and the test set to your friend. For some reason the data set gets corrupted during the transmission. Your friend gets a corrupted training set where only one data point is different. For this third data point, it changed from the label \"yes\" to the label \"no\".\\n\\nThis is a tiny change to the training set, but how would this change affect the decision tree that we generate?\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n\\n3\\nOvercast\\nHot\\nHigh\\nWeak\\nNo\\n\\n4\\nRain\\nMild\\nHigh\\nWeak\\nYes\\n\\n5\\nRain\\nCool\\nNormal\\nWeak\\nYes\\n\\n6\\nRain\\nCool\\nNormal\\nStrong\\nNo\\n\\n7\\nOvercast\\nCool\\nNormal\\nStrong\\nYes\\n\\n8\\nSunny\\nMild\\nHigh\\nWeak\\nNo\\n\\n9\\nSunny\\nCool\\nNormal\\nWeak\\nYes\\n\\n10\\nRain\\nMild\\nNormal\\nWeak\\nYes\\n\\n11\\nSunny\\nMild\\nNormal\\nStrong\\nYes\\n\\n12\\nOvercast\\nMild\\nHigh\\nStrong\\nYes\\n\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n\\n14\\nRain\\nMild\\nHigh\\nStrong\\nNo\\n\\n## Decision Tree generated by the learner algorithm:\\n---\\n# Lecture 7 - Outlook\\n\\n# Lecture 7 - Outlook\\n\\n| | |Outlook|\\n|---|---|---|\\n|Humidity|Sunny|Overcast|Rain|\\n|High|No|Yes|Yes|\\n|Normal|Yes|No|Yes|\\n|Wind| | |Weak|Strong|\\n|No| | |Strong| | |\\n| | | |Yes| |Weak|Yes|\\n\\nWe grew an entire middle sub-tree to accommodate one corrupted data point, and this small corruption caused a dramatic change to the tree. This new tree is more complicated and it likely won’t generalize well to unseen data.\\n\\nThe decision tree learner algorithm is a perfectionist. The algorithm will keep growing the tree until it perfectly classifies all the examples in the training set. However, this is not necessarily a desirable behavior and this can easily lead to over-fitting.\\n\\nThe new test error is 2/14.\\n\\n## 7.2 Dealing with over-fitting with pruning\\n\\nIt would be better to grow a smaller and shallower tree. The smaller and shallower tree may not predict all of the training data points perfectly but it may generalize to test data better. At a high level we have two options to prevent over-fitting when learning a decision tree:\\n\\n- Pre-pruning: stop growing the tree early.\\n\\nIf we decide not to split the examples at a node and stop growing the tree there, we may still have examples with different labels. At this point, we can decide to use the majority label as the decision for that leaf node. Here are some criteria we can use:\\n\\n1. Maximum depth: We can decide not to split the examples if the depth of that node has reached a maximum value that we decided beforehand.\\n2. Minimum number of examples at the leaf node: We can decide not to split the examples if the number of examples remaining at that node is less than a predefined threshold value.\\n\\n© Alice Gao 2021 - v1.0 - Page 33 of 36\\n---\\n# Lecture 7 Summary\\n\\n# Lecture 7 Summary\\n\\nBelow are key points discussed in Lecture 7:\\n\\nPoint\\nDescription\\n\\nMinimum Information Gain\\nWe can decide not to split the examples if the expected information gain is less than a threshold.\\n\\nReduction in Training Error\\nDecide not to split examples if the reduction in training error is below a predefined threshold.\\n\\nPre-Pruning\\nSplit examples at a node only when it\\'s useful, can be used with the criteria above.\\n\\nPost-Pruning\\nGrow a full tree first and then trim it afterwards, useful when multiple features together are informative.\\n\\n## Example:\\n\\nConsider a dataset with two binary input features and the target feature is the XOR function of the inputs.\\n\\nEach input feature alone provides no information about the target, but together they determine the target.\\n\\n### Pre-Pruning:\\n\\nTesting each input feature individually gives zero information, leading to a tree with only the root node predicting randomly.\\n\\n### Post-Pruning:\\n\\nGrowing a full tree first by testing both input features, then pruning nodes if necessary. In this example, no pruning is needed as the second input feature provides all the information.\\n\\nPost-pruning is beneficial when multiple features together are informative.\\n\\nNote: Post-pruning is applied only to nodes with leaf nodes as descendants.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 34 of 36\\n---\\ntable {\\nwidth: 100%;\\nborder-collapse: collapse;\\n}\\n\\ntable, th, td {\\nborder: 1px solid black;\\n}\\n\\nth, td {\\npadding: 10px;\\ntext-align: left;\\n}\\n\\n## CS 486/686 - Lecture 7\\n\\n|Example:|Suppose we are considering post-pruning with the minimal information gain metric.|\\n|---|---|\\n|Process:|1. Restrict attention to nodes with only leaf nodes as descendants.\\n2. If expected information gain < threshold, delete children (all leaf nodes) and convert node to leaf.\\n3. Ensure examples with different labels at this node for majority decision.\\n|\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 35 of 36\\n---\\ntable {\\nwidth: 100%;\\nborder-collapse: collapse;\\n}\\n\\ntable, th, td {\\nborder: 1px solid black;\\n}\\n\\nth, td {\\npadding: 10px;\\ntext-align: left;\\n}\\n\\n## CS 486/686 - Lecture 7 - Practice Problems\\n\\nPractice Problems\\n\\n1. 1. When learning pe tree, we chose a feature to test at each step by maximizing pe expected information gain. Does pis approach allow us to generate pe optimal decision tree? Why or why not?\\n2. 2. Consider a data-set wip real-valued features. Suppose pat we perform binary splits only when building a decision tree.\\n\\na) Is it possible to encounter pe “no features left” base case? Why?\\n\\nb) Is it possible to encounter pe “no examples left” base case? Why?\\n3. 3. What is pe main advantage of post-pruning over pre-pruning?\\n\\n© Alice Gao 2021 - v1.0 - Page 36 of 36', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
          ]
        }
      ],
      "source": [
        "pd=load_or_parse_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aN_dVVmdC2HY",
        "outputId": "8a17b0cb-8c4e-4d90-a162-548627745123"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "type(pd)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vm1nQHrCDBQ5"
      },
      "outputs": [],
      "source": [
        "pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KsSiXJerJxh2"
      },
      "outputs": [],
      "source": [
        "# Create vector database\n",
        "def create_vector_database():\n",
        "    \"\"\"\n",
        "    Creates a vector database using document loaders and embeddings.\n",
        "\n",
        "    This function loads urls,\n",
        "    splits the loaded documents into chunks, transforms them into embeddings using OllamaEmbeddings,\n",
        "    and finally persists the embeddings into a Chroma vector database.\n",
        "\n",
        "    \"\"\"\n",
        "    # Call the function to either load or parse the data\n",
        "    llama_parse_documents = load_or_parse_data()\n",
        "    #print(llama_parse_documents[0].text[:300])\n",
        "\n",
        "    with open('data/output.md', 'a') as f:  # Open the file in append mode ('a')\n",
        "        for doc in llama_parse_documents:\n",
        "            f.write(doc.text + '\\n')\n",
        "\n",
        "    markdown_path = \"/content/data/output.md\"\n",
        "    loader = UnstructuredMarkdownLoader(markdown_path)\n",
        "\n",
        "   #loader = DirectoryLoader('data/', glob=\"**/*.md\", show_progress=True)\n",
        "    documents = loader.load()\n",
        "    # Split loaded documents into chunks\n",
        "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=100)\n",
        "    docs = text_splitter.split_documents(documents)\n",
        "\n",
        "    #len(docs)\n",
        "    print(f\"length of documents loaded: {len(documents)}\")\n",
        "    print(f\"total number of document chunks generated :{len(docs)}\")\n",
        "    #docs[0]\n",
        "\n",
        "    # Initialize Embeddings\n",
        "    embed_model = FastEmbedEmbeddings(model_name=\"BAAI/bge-base-en-v1.5\")\n",
        "\n",
        "    # Create and persist a Chroma vector database from the chunked documents\n",
        "    vs = Chroma.from_documents(\n",
        "        documents=docs,\n",
        "        embedding=embed_model,\n",
        "        persist_directory=\"chroma_db_llamaparse1\",  # Local mode with in-memory storage only\n",
        "        collection_name=\"rag\"\n",
        "    )\n",
        "\n",
        "\n",
        "    print('Vector DB created successfully !')\n",
        "    return vs,embed_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 468,
          "referenced_widgets": [
            "93a9fee5d80e463fa7ddd6dda91031c2",
            "c37d2e4629384eddaae629e5d32e9b61",
            "dd14f2dbd6b14157afd08e46c0b7e7b2",
            "98783ad5506b4c6e9da29f2f99146c44",
            "e54772a611fe4ea1a59617d6b31138b9",
            "3fdd6f028102430a8dac1891e65cb7f4",
            "8cc7c8d4e08f4d44bd700b96b2e985ff",
            "73ff963bf61b499b904713e61984365c",
            "75acd162553044abb0ede44a93eb0980",
            "ecd4fee8e16b415fa3fa7e7aabcacfb7",
            "f217b574934a475e85be163e57874477",
            "0d9fe7612908447e952dda5dabcc1d12",
            "50315b269dc044b58a3a64d8263b1778",
            "ecf8f52d5f5e4da8b2a1ecea50d02f84",
            "cd6e37718c9e4ba999d8fc9377d70a31",
            "6c6e928c9687426faf5bc69f35b2a81f",
            "748b7688d8634a2cad3dbd7878c443d0",
            "cbfc1e74f15047c5bd71caf817a70047",
            "cd469d30dbcc4d0d9dce8b8ee93560c1",
            "45a539ac3e094fa8a788950cbb8f2265",
            "d49d79be6aea44de9dd58fc7cdda8ca5",
            "464a48743f2041ea83a0c8fbcf57d338",
            "b1e1b6f9d86446cc8cd29bf19a91a268",
            "d97422a7031144edb60297f60012c993",
            "558e43ab7f07438dac7fcc25c83dc9d4",
            "c2918974b8fd4b72842cfb15d04db461",
            "e006bdbc7f054f7a8cf98319f982efe4",
            "df91131b95724a72b96164c567e2f5c6",
            "1ec8416f6fb04a818238582ca0e5f6bc",
            "3588c2718b204bd394353ffe02435976",
            "2a0c560aa05a4cf986b36a8117a906a5",
            "f648cc320fe3498a909eed9c31d50220",
            "2d56cecd509142d1809414d902552d78",
            "b2718b8371614ef0a5b4f11af9cae152",
            "15509c24676441b6be900c19bd400c15",
            "d7035b8868cb42339334f85acba121ad",
            "6587127b35fe4d2282c564d35b877565",
            "082132fc225c46b08e559f1614af755c",
            "e3b2ce1b1f484b1f9e62e90cc3740f23",
            "82e75671196c4b809aa340a32bfbfe59",
            "66678d6523b8434b8212e4428a2f185d",
            "78b98b90d9b8449b8253853a4d9fa2bc",
            "4dfa9f22e06c4095932609f3a46a6d3f",
            "338f33ce9f7e4b3ba301bddea816584a",
            "4ca879d912564375a96751eff46045c0",
            "9282d14135a440baa634de1eae63bbfc",
            "5c7cf9abcfde4fc29b6ef7f67f2d1528",
            "5a65ce696fd94cc5a4b41b76ec0e3dcd",
            "522c868fc1f543318fbc4f8fe51ae9d8",
            "da51a2dd1beb43ec873f9981d9abce70",
            "4e8f23577d4b4f7f8dc24b4e67bbee39",
            "f8f8a8027e254cf987d508bacfa1b8fb",
            "928873ab61b84fe8a8e4225ba4f99dbf",
            "f31f03da91004b3b879c60b02f9658fd",
            "0ae548875b2649bb9dc994f02ef743b9",
            "8560f18caa654018bc5f70c6c9154d1f",
            "88d043489bb744459ed1256f74935c3a",
            "323cace826db45c38c755f5412f9bb1c",
            "802dd47a08eb46fea8afcc7638cfd182",
            "856e0b6bf1a648ea962234c31f8e0b7b",
            "d6251768a24c493f8c499de72acc5468",
            "af89e3cc2b5c4408b562e2d1e5d559c6",
            "7a40e368a6364599951798abc32f0762",
            "1c540824311d413990a075f5dac79cbc",
            "9f3148fbbe124f7eac5dd8bdf04f0591",
            "3499cc2930d6400d83175e729e7bd863"
          ]
        },
        "id": "GEyF_DRcN8E3",
        "outputId": "4ae6ad2c-28e6-43d6-d112-4702a962c1ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[Document(id_='83d70dfe-de2f-4020-b277-76a0f61ce44e', embedding=None, metadata={}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, text='# Decision Trees Lecture\\n\\n# Lecture 7: Decision Trees\\n\\n|Contents|\\n|---|\\n|1 Learning Goals|3|\\n|2 Examples of Decision Trees|3|\\n|3 Definition and Classifying an Example|7|\\n|3.1 What is a decision tree?|7|\\n|3.2 Classifying an example using a decision tree|7|\\n|4 The Decision Tree Learning Algorithm|8|\\n|4.1 Issues in learning a decision tree|8|\\n|4.2 Grow a full tree given an order of testing features|8|\\n|4.3 When do we stop?|11|\\n|4.4 Base case 2: no features left|11|\\n|4.5 Base case 3: no examples left|13|\\n|4.6 Pseudo-code for the decision tree learner algorithm|15|\\n|5 Determine the Order of Testing Features|16|\\n|5.1 Which feature should we test at each step?|16|\\n|5.2 Identifying the most important feature|16|\\n|5.3 Entropy of a distribution over two outcomes|17|\\n|5.4 Expected information gain of testing a feature|19|\\n|5.5 A full example|20|\\n|6 Real-Valued Features|26|\\n|6.1 Jeeves dataset with real-valued temperatures|26|\\n|6.2 Handling a discrete feature|27|\\n|6.3 Handling a real-valued feature|28|\\n|6.4 Choosing a split point for a real-valued feature|28|\\n|7 Over-fitting|31|\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\nTopic\\nPage\\n\\nCorrupted data in the Jeeves dataset\\n31\\n\\nDealing with over-fitting with pruning\\n33\\n\\n## Practice Problems\\n\\n© Alice Gao 2021 - v1.0 - Page 2 of 36\\n---\\n# Decision Trees Lecture\\n\\n# Lecture 7\\n\\n## Learning Goals\\n\\nLearning Objectives\\nDescribe pe components of a decision tree.\\nConstruct a decision tree given an order of testing pe features.\\nDetermine pe prediction accuracy of a decision tree on a test set.\\nCompute pe entropy of a probability distribution.\\nCompute pe expected information gain for selecting a feature.\\nTrace pe execution of and implement pe ID3 algoripm.\\n\\n## Examples of Decision Trees\\n\\nOur first machine learning algorithm will be decision trees. A decision tree is a very common algorithm that we humans use to make many different decisions. You may be using one without realizing it. Here are some examples of decision trees:\\n\\nDecision Tree Example: Which language should you learn?\\n\\nWHICH LANGUAGE\\nSHOULD YOU LEARN IN 2018?\\nUSEFUL\\nOR\\nCOOL\\nEASY\\nOR\\nHARD\\nHIPSTER\\nOR\\nPHONETICS\\nOR\\nGRAMMAR\\nMANDARIN\\nHOLA\\nSPANISH\\nJAPANESE\\nCULTURETRIPCOM\\nv1.0\\n---\\n# Pet Selection Quiz\\n\\n# Pet Selection Quiz\\n\\nQuestion\\nAnswer\\n\\nDo you want a pet to love and care for?\\nYES\\n\\nAre you likely to forget you have a pet?\\nNO\\n\\nDo you want a creature that returns your affection?\\nYES\\n\\nDo you want to train your pet to do things?\\nYES\\n\\nDo you have a large open field?\\nYES\\n---\\n# CS 486/686 Lecture 7\\n\\nQuestion\\nAnswer\\n\\nExample: Should you use emoji in a conversation?\\nShould I Use Emoji in a conversation?\\n\\nAre individuals under 20 years old?\\nYes\\n\\nAre individuals over 65 years old?\\nNo\\n\\nIs this work-related?\\nNo\\n\\nAre individuals over 40 years old geeky?\\nNo\\n\\nWill you like being interrupted?\\nNo\\n\\nAre you trying to avoid making people feel alienated?\\nYes\\n\\nAre you being the smartest person in the room?\\nNo\\n\\nDo not use\\nIdiot\\n---\\n# Lecture 7\\n\\n# Example Data for Tennis Prediction\\n\\nTraining Set\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n\\n14\\nRain\\nMild\\nHigh\\nStrong\\nNo\\n\\nTest Set\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\nMild\\nHigh\\nStrong\\nNo\\n\\n2\\nRain\\nHot\\nNormal\\nStrong\\nNo\\n\\n3\\nRain\\nCool\\nHigh\\nStrong\\nNo\\n\\n4\\nOvercast\\nHot\\nHigh\\nStrong\\nYes\\n\\n5\\nOvercast\\nCool\\nNormal\\nWeak\\nYes\\n\\n6\\nRain\\nHot\\nHigh\\nWeak\\nYes\\n\\n7\\nOvercast\\nMild\\nNormal\\nWeak\\nYes\\n\\n8\\nOvercast\\nCool\\nHigh\\nWeak\\nYes\\n\\n9\\nRain\\nCool\\nHigh\\nWeak\\nYes\\n\\n10\\nRain\\nMild\\nNormal\\nStrong\\nNo\\n\\n11\\nOvercast\\nMild\\nHigh\\nWeak\\nYes\\n\\n12\\nSunny\\nMild\\nNormal\\nWeak\\nYes\\n\\n13\\nSunny\\nCool\\nHigh\\nStrong\\nNo\\n\\n14\\nSunny\\nCool\\nHigh\\nWeak\\nNo\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\n3.1 What is a decision tree?\\n\\nA decision tree is a simple model for supervised classification. It is used for classifying a single discrete target feature. Each internal node performs a Boolean test on an input feature. The edges are labeled wip pe values of pat input feature. Each leaf node specifies a value for pe target feature.\\n\\n3.2 Classifying an example using a decision tree\\n\\nClassifying an example using a decision tree is very intuitive. We traverse down pe tree, evaluating each test and following pe corresponding edge. When a leaf is reached, we return pe classification on pat leaf.\\n\\n### Example:\\n\\nHere is an example of using the emoji decision tree. Assume:\\n\\n- I am 30 years old.\\n- This is work related.\\n- I am an accountant.\\n- I am not trying to get fired.\\n\\nFollowing the tree, we answer no (not under 20 years old), no (not over 65 years old), yes (work related), no (not working in tech), and no (not trying to get fired). The leaf we reach is a thumb down, meaning we should not use emoji.\\n\\n### Problem:\\n\\nIf we convert a decision tree to a program, what does it look like?\\n\\n### Solution:\\n\\nA decision tree corresponds to a program with a big nested if-then-else structure.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 7 of 36\\n---\\n# Decision Tree Learning Algorithm\\n\\n# CS 486/686 - Lecture 7\\n\\n## 4. The Decision Tree Learning Algorithm\\n\\n### 4.1 Issues in learning a decision tree\\n\\nHow can we build a decision tree given a data set? First, we need to decide on an order of testing the input features. Next, given an order of testing the input features, we can build a decision tree by splitting the examples whenever we test an input feature.\\n\\nLet’s take a look at the Jeeves training set again. Each row is an example. There are 14 examples. For each example, we have five feature values: day, outlook, temperature, humidity, and wind. In fact, Day is not a useful feature since it’s different for every example. So, we will focus on the other four input features. We have one target feature or label, which is whether Bertie decided to play tennis or not.\\n\\nThe decision tree is a powerful and flexible model. Given a data set, we can generate many different decision trees. Therefore, there are a few questions we need to think about when deciding which tree we should build.\\n\\nFirst, different orders of testing the input features will lead to different decision trees. So, which order should we use? The number of possible orders is quite large, so it is challenging to find the optimal order in the search space. Given this, we will use a greedy or myopic approach. Instead of finding the optimal order of testing the features, we will make the myopic best choice at each step.\\n\\nYou might be wondering, what is the difference between making the optimal choice versus making the myopic best choice at each step? The main difference is that the optimal strategy considers the future, whereas the myopic strategy only cares about the current step. To generate an optimal tree, at each step, we need to think about how our feature choice at this step might affect our choices in the future. On the contrary, the myopic strategy does not think about the future at all and only cares about finding the best feature to test at the current step.\\n\\nNow, suppose that we have chosen an order of testing the features using the myopic strategy. We have another choice. Should we grow a full tree or should we stop growing the tree earlier? Recall that I discussed over-fitting previously. The full tree may over-fit the training data, so a smaller tree might be better since it might generalize better to unseen test data.\\n\\nTo answer this question, we need a bias or an assumption that we make about which tree we prefer. One possible assumption could be based on Occam’s razor principle, which says that the simplest model or hypothesis is probably the best. Based on Occam’s razor, we would prefer a tree that is smaller than the full tree. This still leaves lots of options for us. For example, we can grow the tree until a certain depth, or we can grow the tree until it has a certain number of nodes.\\n\\n### 4.2 Grow a full tree given an order of testing features\\n\\nLet’s go through an example of constructing the full tree using the Jeeves training set. I’ve given you an order of testing the input features below.\\n\\nOrder of Testing Features\\n1. Outlook\\n2. Temperature\\n3. Humidity\\n4. Wind\\n\\n© Alice Gao 2021 - v1.0 - Page 8 of 36\\n---\\n# Decision Tree Construction\\n\\n# Decision Tree Construction\\n\\nOrder of Testing Features\\n1. Test Outlook\\n2. For Outlook = Sunny, test Temp\\n3. For Outlook = Rain, test Wind\\n4. For oper branches, test Humidity before testing Wind\\n\\n## Problem:\\n\\nConstruct a (full) decision tree for the Jeeves data set using the given order of testing features.\\n\\n### Solution:\\n\\nProcess to generate the decision tree:\\n\\n1. We have 9 positive and 5 negative examples.\\n2. Since the examples are not in the same class, we need to choose a feature to test.\\n3. Based on the order provided, we start by testing Outlook.\\n4. Outlook has three values: Sunny, Overcast, and Rain. We split the examples into three branches accordingly.\\n\\nThe sets after splitting based on Outlook:\\n\\nExample\\nOutlook\\n\\n1\\nSunny\\n\\n2\\nOvercast\\n\\n3\\nRain\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 9 of 36\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\nBranch\\nExamples\\nDecision\\n\\nMiddle\\nAll positive\\nCreate leaf node with label Yes\\n\\nLeft\\n2 positive, 3 negative\\nTest feature Temp\\n\\nWe will repeat this process at every node. First, check if all the examples are in the same class. If they are, create a leaf node with the class label and stop. Otherwise, choose the next feature to test and split the examples based on the chosen feature.\\n\\n© Alice Gao 2021 - v1.0 - Page 10 of 36\\n---\\n# Decision Tree Lecture\\n\\n# Decision Tree Lecture\\n\\n|Temp|Yes|Wind|\\n|---|---|---|\\n|No|Humidity|Yes|Wind|\\n| |No|Yes|Yes|No|\\n\\n## When do we stop?\\n\\nThere are three possible stopping criteria for the decision tree algorithm. For the example in the previous section, we encountered the first case only: when all of the examples belong to the same class. In this case, we make the decision of that class and then we’re done.\\n\\n## Base case 2: no features left\\n\\nLet’s look at the second case: what should we do if there are no more features to test?\\n\\nProblem: I took our training set and added a few examples. It now has 17 instead of 14 examples. For this modified training set, let’s construct one branch of the decision tree where Outlook is Sunny, Temperature is Mild, and Humidity is High.\\n---\\n# CS 486/686 Lecture 7\\n\\n# CS 486/686 Lecture 7\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n\\n16\\nSunny\\nMild\\nHigh\\nWeak\\nYes\\n\\n17\\nSunny\\nMild\\nHigh\\nStrong\\nYes\\n\\nSolution: After testing Humidity is High, the next step is to test the Wind feature. When Wind is Strong, the decision is Yes. When Wind is Weak, there are mixed results, so no decision can be made. In such cases, when all features have been tested, and no clear decision can be reached, one option is to predict the majority class or make a randomized decision.\\n\\nWhen we run out of features to test, and the data set is noisy with conflicting labels for the same input values, we can consider predicting the majority class or making a randomized decision based on the distribution of outcomes.\\n\\nFor the given example, the majority decision when Wind is Weak is No.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 12 of 36\\n---\\n# CS 486/686 Lecture 7\\n\\n## Decision Tree Branch\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n3\\nOvercast\\nHot\\nHigh\\nWeak\\nYes\\n\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n\\n12\\nOvercast\\nMild\\nHigh\\nStrong\\nYes\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\nTemperature\\nOutlook\\nWind\\nHumidity\\nDecision\\n\\nHot\\nSunny\\nWeak\\nHigh\\nNo\\n\\nHot\\nOvercast\\nWeak\\nHigh\\nYes\\n\\nHot\\nRain\\nWeak\\nHigh\\nNo\\n\\nWhen encountering the case where Outlook is Rain and there are no examples left, we need to handle it by considering examples from the parent node.\\n\\nWe can use the examples at the parent node, which are likely to be mixed, to make a decision. This decision can be based on either the majority decision or a random draw from a probability distribution.\\n\\nThis approach helps in situations where certain combinations of feature values are not observed in the dataset, allowing us to still make informed decisions.\\n---\\n# Decision Tree Learner Algorithm\\n\\n## Pseudo-code for the decision tree learner algorithm\\n\\nAlgoripm 1 Decision Tree Learner (examples, features)\\n\\n1. if all examples are in pe same class pen\\n2. return pe class label.\\n3. else if no features left pen\\n4. return pe majority decision.\\n5. else if no examples left pen\\n6. return pe majority decision at pe parent node.\\n7. else\\n8. choose a feature f .\\n9. for each value v of feature f do\\n10. build edge wip label v.\\n11. build sub-tree using examples where pe value of f is v.\\n\\nHere is the pseudocode for the algorithm. Since a tree is recursive, we will naturally use a recursive algorithm to build it.\\n\\nThe algorithm starts with three base cases:\\n\\n1. If all the examples are in the same class, we will return the class label.\\n2. If there are no features left, we have noisy data. We can either return the majority decision or make a decision probabilistically.\\n3. If there are no examples left, then some combination of input features is absent in the training set. We can use the examples at the parent node to make a decision. If the examples are not in the same class, we can either return the majority decision or make a decision probabilistically.\\n\\nNext, we have the recursive part. Suppose that we have a pre-specified order of testing the input features. At each step, we will split up the examples based on the chosen feature’s values. We will label the edges with the feature’s value. Each subtree only has examples where the value of the feature corresponds to the value on the edge.\\n\\nThere’s one crucial step left. So far, we have assumed that a pre-defined order of testing the input features. Where does this order come from? In practice, we have to choose this order ourselves.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 15 of 36\\n---\\n# Lecture 7\\n\\n# CS 486/686 - Lecture 7\\n\\nQuestion\\nAnswer\\n\\n5.1 Which feature should we test at each step?\\nWe should choose a feature that makes the biggest difference to the classification or helps in making a decision quickly. The approach is to minimize the number of features to test by learning a small and shallow tree, using a greedy and myopic approach.\\n\\n5.2 How do we identify the most important feature?\\nTo identify the most important feature, we calculate the reduction in uncertainty by subtracting the uncertainty in examples after testing the feature from the uncertainty before testing the feature. This information content is measured using entropy from information theory, which is calculated based on the probability distribution over outcomes.\\n---\\n# Entropy Calculation Questions\\n\\n# Entropy Calculation Questions\\n\\nProblem\\nOptions\\n\\nWhat is the entropy of the distribution (0.5, 0.5)?\\n- (A) 0.2\\n- (B) 0.4\\n- (C) 0.6\\n- (D) 0.8\\n- (E) 1\\n\\nSolution:\\nThe correct answer is (E).\\n\\nPerforming the calculation, we have:\\n-(0.5 * log2(0.5)) * 2 = 1\\n\\nThe entropy is 1 bit.\\n\\nYou might be wondering, is one bit of entropy a lot or very little? You will get a better idea of this after question 2. For now, believe me when I say that there is a lot of uncertainty in this binary distribution.\\n\\nThis should make intuitive sense. This distribution is uniform. A uniform distribution has a lot of uncertainty since every outcome is equally likely to become true.\\n\\nWhat is the entropy of the distribution (0.01, 0.99)?\\n- (A) 0.02\\n- (B) 0.04\\n- (C) 0.06\\n- (D) 0.08\\n\\nWe have a very skewed distribution. Almost all the probability is on the second outcome.\\n---\\n# Entropy Questions\\n\\n# Entropy Questions\\n\\nProblem\\nSolution\\n\\n1. What is the maximum entropy of the distribution (p, 1 - p) where 0 ≤ p ≤ 1?\\nFor any binary distribution, its entropy achieves its maximum value of one when the distribution is uniform.\\n\\n2. What is the minimum entropy of the distribution (p, 1 - p) where 0 ≤ p ≤ 1?\\nThe entropy achieves its minimum value of zero when the distribution is a point mass — one outcome has a probability of 1.\\n\\n3. Plot the entropy of the distribution (p, 1 - p) with respect to p.\\nAs p increases from 0 to 1, the entropy increases first, reaches the maximum value when p is 0.5, and then decreases after that.\\n---\\n# Lecture 7 Summary\\n\\n# CS 486/686 - Lecture 7 Summary\\n\\n## Practice Question\\n\\nWhat are the maximum and minimum entropy for a distribution with three outcomes?\\n\\n## Expected Information Gain of Testing a Feature\\n\\nHow can we quantify the information content of a feature?\\n\\nFeature Value\\nPositive Examples\\nNegative Examples\\n\\nv1\\nP1\\nN1\\n\\nv2\\nP2\\nN2\\n\\n...\\n...\\n...\\n\\nvk\\nPk\\nNk\\n\\nExpected Information Gain Formula:\\n\\nIbefore = I(p, n) / (p + n)\\n\\nAfter testing the feature, we have k distributions. How do we calculate the entropy of k distributions?\\n---\\n# Decision Tree Example\\n\\n# Decision Tree Example\\n\\nHere, we will work through generating a complete decision tree based on the rules introduced in this section. We can start with the following questions:\\n\\n## Problem:\\n\\nWhat is the entropy of the examples before we select a feature for the root node of the tree?\\n\\nOptions\\nEntropy Value\\n\\n(A)\\n0.54\\n\\n(B)\\n0.64\\n\\n(C)\\n0.74\\n\\n(D)\\n0.84\\n\\n(E)\\n0.94\\n\\n## Solution:\\n\\nThere are 14 examples: 9 positive, 5 negative. Applying the formula gives:\\n\\nHbefore = - (9 log2(9) + 5 log2(5)) / 14\\n\\n= - (9 * (-0.637) + 5 * (-1.485)) / 14\\n\\n= -(-0.939)\\n\\n≈ 0.94\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 20 of 36\\n---\\n# Questions\\n\\n|Problem|Options|\\n|---|---|\\n|What is the expected information gain if we select Outlook as the root node of the tree?|- (A) 0.237\\n- (B) 0.247\\n- (C) 0.257\\n- (D) 0.267\\n- (E) 0.277\\n|\\n|What is the expected information gain if we select Humidity as the root node of the tree?|- (A) 0.151\\n- (B) 0.251\\n|\\n---\\n# Lecture 7\\n\\n## Question:\\n\\nWhat is pe expected information gain for testing Humidity?\\n\\n### Options:\\n\\n(A) 0.151\\n(B) 0.251\\n(C) 0.351\\n(D) 0.451\\n(E) 0.551\\n\\n### Solution:\\n\\nGain(Humidity) = 0.94 - 7 * I(6,1) + 7 * I(3,4)\\n= 0.94 - 7(0.592) + 7(0.985)\\n= 0.94 - 0.78914\\n= 0.151\\n\\nThe correct answer is (A).\\n\\n## Additional Information:\\n\\nComparing Outlook and Humidity, the expected information gain of testing Outlook first is greater than that of testing Humidity first. When comparing features to test at a node, we could simply ignore the entropy before testing and select the feature with the lowest post-testing entropy.\\n\\n### Example:\\n\\nFor the root node, the expected information gain for testing different features is as follows:\\n\\nGain(Outlook) = 0.247\\nGain(Humidity) = 0.151\\nGain(Temp) = 0.029\\nGain(Wind) = 0.048\\n\\nWe pick Outlook since it has the greatest expected information gain.\\n\\n© Alice Gao 2021 - v1.0 - Page 22 of 36\\n---\\n# Lecture 7\\n\\n# Decision Tree Analysis\\n\\n|Case 1|Outlook = Sunny|\\n|---|---|\\n|Hot|+ : 9, 11|- : 1, 2, 8|\\n| |Mild|+ : 11|- : 8|\\n| |Cool|+ : 9|-|\\n\\nGain(Temp) = 0.57\\n\\n|Humidity|\\n|---|\\n|High|+ :|- : 1, 2, 8|\\n|Normal|+ : 9, 11|-|\\n\\nGain(Humidity) = 0.97\\n\\n|Wind|\\n|---|\\n|Weak|+ : 9|- : 11|\\n|Strong|+ : 1, 8|- : 2|\\n\\nGain(Wind) = 0.019\\n\\nWe pick Humidity since it has the greatest expected information gain. This makes sense since the positive and negative examples are completely separated after testing Humidity.\\n\\n|Case 2|Outlook = Overcast|\\n|---|---|\\n| |+ : 3, 7, 12, 13|-|\\n---\\n# Lecture 7\\n\\n# Decision Tree Analysis\\n\\nCase\\nOutlook\\nTemp\\nHumidity\\nWind\\n\\n1\\nSunny\\nHot\\nHigh\\nWeak\\n\\n2\\nSunny\\nHot\\nHigh\\nStrong\\n\\n3\\nRain\\nMild\\nHigh\\nWeak\\n\\n4\\nRain\\nCool\\nNormal\\nWeak\\n\\n5\\nRain\\nMild\\nNormal\\nWeak\\n\\n6\\nSunny\\nMild\\nHigh\\nWeak\\n\\n7\\nSunny\\nCool\\nNormal\\nStrong\\n\\n8\\nRain\\nMild\\nHigh\\nStrong\\n\\n9\\nSunny\\nMild\\nNormal\\nWeak\\n\\n10\\nRain\\nMild\\nNormal\\nWeak\\n\\nWe pick Wind since it has the greatest expected information gain. This makes sense since the positive and negative examples are completely separated after testing Wind.\\n\\nThe final decision tree is drawn below:\\n\\n© Alice Gao 2021 | v1.0 | Page 24 of 36\\n---\\n# Decision Tree - Outlook, Humidity, Wind\\n\\n# Decision Tree - Weather Conditions\\n\\nOutlook\\nHumidity\\nWind\\n\\n1\\nSunny\\nHigh\\nWeak\\n\\n2\\nSunny\\nHigh\\nStrong\\n\\n3\\nOvercast\\n\\n4\\nRain\\nNormal\\nWeak\\n\\n5\\nRain\\nNormal\\n\\n6\\nRain\\n\\nStrong\\n\\n7\\nOvercast\\n\\n8\\nSunny\\nHigh\\n\\n9\\nSunny\\nNormal\\nWeak\\n\\n10\\nRain\\nNormal\\nWeak\\n\\n11\\nSunny\\nNormal\\nWeak\\n\\n12\\nOvercast\\n\\n13\\nOvercast\\n\\n14\\nRain\\n\\nStrong\\n---\\n# Lecture 7 - Real-Valued Features\\n\\n# CS 486/686 - Lecture 7\\n\\n## Real-Valued Features\\n\\n### Jeeves dataset with real-valued temperatures\\n\\nSo far, the decision tree learner algorithm only works when all of the features have discrete values. In the real world, we are going to encounter a lot of data sets where many features have continuous values, or they’re real-valued. Let’s see how decision trees can handle them.\\n\\n#### Example: A more realistic Jeeves dataset with real-valued temperatures\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\n29.4\\nHigh\\nWeak\\nNo\\n\\n2\\nSunny\\n26.6\\nHigh\\nStrong\\nNo\\n\\n3\\nOvercast\\n28.3\\nHigh\\nWeak\\nYes\\n\\n4\\nRain\\n21.1\\nHigh\\nWeak\\nYes\\n\\n5\\nRain\\n20.0\\nNormal\\nWeak\\nYes\\n\\n6\\nRain\\n18.3\\nNormal\\nStrong\\nNo\\n\\n7\\nOvercast\\n17.7\\nNormal\\nStrong\\nYes\\n\\n8\\nSunny\\n22.2\\nHigh\\nWeak\\nNo\\n\\n9\\nSunny\\n20.6\\nNormal\\nWeak\\nYes\\n\\n10\\nRain\\n23.9\\nNormal\\nWeak\\nYes\\n\\n11\\nSunny\\n23.9\\nNormal\\nStrong\\nYes\\n\\n12\\nOvercast\\n22.2\\nHigh\\nStrong\\nYes\\n\\n13\\nOvercast\\n27.2\\nNormal\\nWeak\\nYes\\n\\n14\\nRain\\n21.7\\nHigh\\nStrong\\nNo\\n\\nInstead of having the temperature being a discrete feature, having three values: Mild, Hot, and Cool, we will use actual numbers for Temperature.\\n\\nFor convenience, we will reorder the data set based on the value of the Temperature.\\n\\n#### Example: Jeeves dataset ordered by temperatures\\n\\n© Alice Gao 2021 - v1.0 - Page 26 of 36\\n---\\n# Lecture 7\\n\\n## Day Outlook Temp Humidity Wind Tennis?\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n7\\nOvercast\\n17.7\\nNormal\\nStrong\\nYes\\n\\n6\\nRain\\n18.3\\nNormal\\nStrong\\nNo\\n\\n5\\nRain\\n20.0\\nNormal\\nWeak\\nYes\\n\\n9\\nSunny\\n20.6\\nNormal\\nWeak\\nYes\\n\\n4\\nRain\\n21.1\\nHigh\\nWeak\\nYes\\n\\n14\\nRain\\n21.7\\nHigh\\nStrong\\nNo\\n\\n8\\nSunny\\n22.2\\nHigh\\nWeak\\nNo\\n\\n12\\nOvercast\\n22.2\\nHigh\\nStrong\\nYes\\n\\n10\\nRain\\n23.9\\nNormal\\nWeak\\nYes\\n\\n11\\nSunny\\n23.9\\nNormal\\nStrong\\nYes\\n\\n2\\nSunny\\n26.6\\nHigh\\nStrong\\nNo\\n\\n13\\nOvercast\\n27.2\\nNormal\\nWeak\\nYes\\n\\n3\\nOvercast\\n28.3\\nHigh\\nWeak\\nYes\\n\\n1\\nSunny\\n29.4\\nHigh\\nWeak\\nNo\\n\\n## Handling a discrete feature\\n\\nBefore seeing how we can handle real-valued features, let’s review how we can handle a discrete feature. We considered two options:\\n\\n- Allow multi-way splits:\\n- The tree becomes more complex than just if-then-else.\\n- The tree tends to be shallower.\\n- The expected information gain metric prefers a variable with a larger domain, because when a variable has a larger domain we can split the data points into more sets, and there’s a higher chance to reduce entropy.\\n- Restrict to binary splits:\\n- The tree is simpler and more compact.\\n- The tree tends to be deeper.\\n\\nExample: As an extreme example, pretend that Day is an additional input feature in the Jeeves dataset, then the expected information gain for splitting on day must be the largest. Since we have one example for each day, and we can make a deterministic decision right away after splitting on day. However, it clearly does not make sense to use day as a feature, as the resulting tree does not generalize to any other data sets.\\n\\n&copy; Alice Gao 2021 | v1.0 | Page 27 of 36\\n---\\n# Lecture 7 Summary\\n\\n# CS 486/686 - Lecture 7 Summary\\n\\n## Handling a real-valued feature\\n\\nMethods for handling a real-valued feature\\nConsiderations\\n\\nDiscretize the feature\\nEasy to implement but may lose valuable information\\n\\nAllow multi-way splits\\nImpractical due to unbounded feature domain\\n\\nRestrict to binary splits\\nChoose split points dynamically; may lead to deeper trees\\n\\n## Choosing a split point for a real-valued feature\\n\\nA na&iuml;ve way to choose a split point:\\n\\n1. Sort instances by the real-valued feature\\n2. Consider midpoints of consecutive values as possible split points\\n3. Calculate expected information gain for each split point\\n4. Pick the split point with the greatest expected information gain\\n\\nSmarter approach:\\n\\n1. Sort instances by the real-valued feature\\n2. Identify possible split points as midway between different adjacent values\\n3. Consider (X + Y)/2 as a split point if labels differ between X and Y\\n\\nExample: With the modified Jeeves data set, there are 11 possible split points using the na&iuml;ve method.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 28 of 36\\n---\\n# Information Gain and Split Points\\n\\n# Information Gain and Split Points\\n\\nProblem\\nQuestion\\n\\nFor the Jeeves training set, is the midpoint between 20.0 and 20.6 a possible split point?\\n(A) Yes (B) No\\n\\nSolution\\nThis is not a possible split point: L= {Yes} and L= {Yes}. 20.0 20.6 The correct answer is (B).\\n\\nProblem\\nFor the Jeeves training set, is the midpoint between 21.1 and 21.7 a possible split point?\\n\\nQuestion\\n(A) Yes (B) No\\n\\nSolution\\nThis is a possible split point: L= {Yes} and L= {No}. 21.1 21.7 The correct answer is (A).\\n\\nProblem\\nFor the Jeeves training set, is the midpoint between 21.7 and 22.2 a possible split point?\\n\\nQuestion\\n(A) Yes (B) No\\n\\nSolution\\nThe correct answer is (B).\\n\\n©c Alice Gao 2021 v1.0 Page 29 of 36\\n---\\ntable {\\nwidth: 100%;\\nborder-collapse: collapse;\\n}\\ntable, th, td {\\nborder: 1px solid black;\\n}\\nth, td {\\npadding: 10px;\\ntext-align: left;\\n}\\n\\n## Question:\\n\\nQuestion 21:\\nWhat is a possible split point according to the solution provided?\\n\\n## Answer:\\n\\nAnswer:\\nA possible split point is L = {No} and L = {No, Yes}.\\n\\n## Explanation:\\n\\nExplanation:\\nIntuitively, the procedure considers local changes at each midway point. If the target feature doesn’t change locally, that point probably isn’t a valuable split point.\\n---\\n# Lecture 7: Over-fitting\\n\\n# CS 486/686 - Lecture 7\\n\\n## 7. Over-fitting\\n\\n### 7.1 Corrupted data in the Jeeves dataset\\n\\nOver-fitting is a common problem when learning a decision tree. Decision trees have several advantages in supervised machine learning, such as simplicity, ease of understanding, and interpretability.\\n\\nWhile decision trees are good for explaining models to humans, neural networks can be complex and hard to interpret. Decision trees can also work well with small datasets, unlike neural networks which are prone to over-fitting with limited data.\\n\\nDespite the benefits of decision trees, over-fitting remains a challenge during construction.\\n\\n#### Example: The Jeeves dataset\\n\\n|Day|Outlook|Temp|Humidity|Wind|Tennis?|\\n|---|---|---|---|---|---|\\n|1|Sunny|Hot|High|Weak|No|\\n|2|Sunny|Hot|High|Strong|No|\\n|3|Overcast|Hot|High|Weak|Yes|\\n|4|Rain|Mild|High|Weak|Yes|\\n|5|Rain|Cool|Normal|Weak|Yes|\\n|6|Rain|Cool|Normal|Strong|No|\\n|7|Overcast|Cool|Normal|Strong|Yes|\\n|8|Sunny|Mild|High|Weak|No|\\n|9|Sunny|Cool|Normal|Weak|Yes|\\n|10|Rain|Mild|Normal|Weak|Yes|\\n|11|Sunny|Mild|Normal|Strong|Yes|\\n|12|Overcast|Mild|High|Strong|Yes|\\n|13|Overcast|Hot|Normal|Weak|Yes|\\n|14|Rain|Mild|High|Strong|No|\\n\\nDecision tree generated by the learner algorithm:\\n\\n© Alice Gao 2021 - v1.0 - Page 31 of 36\\n---\\n# Lecture 7 - Decision Tree\\n\\n# Decision Tree Analysis\\n\\nTest error is 0 out of 14.\\n\\nExample: Suppose that you sent the training set and the test set to your friend. For some reason the data set gets corrupted during the transmission. Your friend gets a corrupted training set where only one data point is different. For this third data point, it changed from the label \"yes\" to the label \"no\".\\n\\nThis is a tiny change to the training set, but how would this change affect the decision tree that we generate?\\n\\nDay\\nOutlook\\nTemp\\nHumidity\\nWind\\nTennis?\\n\\n1\\nSunny\\nHot\\nHigh\\nWeak\\nNo\\n\\n2\\nSunny\\nHot\\nHigh\\nStrong\\nNo\\n\\n3\\nOvercast\\nHot\\nHigh\\nWeak\\nNo\\n\\n4\\nRain\\nMild\\nHigh\\nWeak\\nYes\\n\\n5\\nRain\\nCool\\nNormal\\nWeak\\nYes\\n\\n6\\nRain\\nCool\\nNormal\\nStrong\\nNo\\n\\n7\\nOvercast\\nCool\\nNormal\\nStrong\\nYes\\n\\n8\\nSunny\\nMild\\nHigh\\nWeak\\nNo\\n\\n9\\nSunny\\nCool\\nNormal\\nWeak\\nYes\\n\\n10\\nRain\\nMild\\nNormal\\nWeak\\nYes\\n\\n11\\nSunny\\nMild\\nNormal\\nStrong\\nYes\\n\\n12\\nOvercast\\nMild\\nHigh\\nStrong\\nYes\\n\\n13\\nOvercast\\nHot\\nNormal\\nWeak\\nYes\\n\\n14\\nRain\\nMild\\nHigh\\nStrong\\nNo\\n\\n## Decision Tree generated by the learner algorithm:\\n---\\n# Lecture 7 - Outlook\\n\\n# Lecture 7 - Outlook\\n\\n| | |Outlook|\\n|---|---|---|\\n|Humidity|Sunny|Overcast|Rain|\\n|High|No|Yes|Yes|\\n|Normal|Yes|No|Yes|\\n|Wind| | |Weak|Strong|\\n|No| | |Strong| | |\\n| | | |Yes| |Weak|Yes|\\n\\nWe grew an entire middle sub-tree to accommodate one corrupted data point, and this small corruption caused a dramatic change to the tree. This new tree is more complicated and it likely won’t generalize well to unseen data.\\n\\nThe decision tree learner algorithm is a perfectionist. The algorithm will keep growing the tree until it perfectly classifies all the examples in the training set. However, this is not necessarily a desirable behavior and this can easily lead to over-fitting.\\n\\nThe new test error is 2/14.\\n\\n## 7.2 Dealing with over-fitting with pruning\\n\\nIt would be better to grow a smaller and shallower tree. The smaller and shallower tree may not predict all of the training data points perfectly but it may generalize to test data better. At a high level we have two options to prevent over-fitting when learning a decision tree:\\n\\n- Pre-pruning: stop growing the tree early.\\n\\nIf we decide not to split the examples at a node and stop growing the tree there, we may still have examples with different labels. At this point, we can decide to use the majority label as the decision for that leaf node. Here are some criteria we can use:\\n\\n1. Maximum depth: We can decide not to split the examples if the depth of that node has reached a maximum value that we decided beforehand.\\n2. Minimum number of examples at the leaf node: We can decide not to split the examples if the number of examples remaining at that node is less than a predefined threshold value.\\n\\n© Alice Gao 2021 - v1.0 - Page 33 of 36\\n---\\n# Lecture 7 Summary\\n\\n# Lecture 7 Summary\\n\\nBelow are key points discussed in Lecture 7:\\n\\nPoint\\nDescription\\n\\nMinimum Information Gain\\nWe can decide not to split the examples if the expected information gain is less than a threshold.\\n\\nReduction in Training Error\\nDecide not to split examples if the reduction in training error is below a predefined threshold.\\n\\nPre-Pruning\\nSplit examples at a node only when it\\'s useful, can be used with the criteria above.\\n\\nPost-Pruning\\nGrow a full tree first and then trim it afterwards, useful when multiple features together are informative.\\n\\n## Example:\\n\\nConsider a dataset with two binary input features and the target feature is the XOR function of the inputs.\\n\\nEach input feature alone provides no information about the target, but together they determine the target.\\n\\n### Pre-Pruning:\\n\\nTesting each input feature individually gives zero information, leading to a tree with only the root node predicting randomly.\\n\\n### Post-Pruning:\\n\\nGrowing a full tree first by testing both input features, then pruning nodes if necessary. In this example, no pruning is needed as the second input feature provides all the information.\\n\\nPost-pruning is beneficial when multiple features together are informative.\\n\\nNote: Post-pruning is applied only to nodes with leaf nodes as descendants.\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 34 of 36\\n---\\ntable {\\nwidth: 100%;\\nborder-collapse: collapse;\\n}\\n\\ntable, th, td {\\nborder: 1px solid black;\\n}\\n\\nth, td {\\npadding: 10px;\\ntext-align: left;\\n}\\n\\n## CS 486/686 - Lecture 7\\n\\n|Example:|Suppose we are considering post-pruning with the minimal information gain metric.|\\n|---|---|\\n|Process:|1. Restrict attention to nodes with only leaf nodes as descendants.\\n2. If expected information gain < threshold, delete children (all leaf nodes) and convert node to leaf.\\n3. Ensure examples with different labels at this node for majority decision.\\n|\\n\\n&copy; Alice Gao 2021 - v1.0 - Page 35 of 36\\n---\\ntable {\\nwidth: 100%;\\nborder-collapse: collapse;\\n}\\n\\ntable, th, td {\\nborder: 1px solid black;\\n}\\n\\nth, td {\\npadding: 10px;\\ntext-align: left;\\n}\\n\\n## CS 486/686 - Lecture 7 - Practice Problems\\n\\nPractice Problems\\n\\n1. 1. When learning pe tree, we chose a feature to test at each step by maximizing pe expected information gain. Does pis approach allow us to generate pe optimal decision tree? Why or why not?\\n2. 2. Consider a data-set wip real-valued features. Suppose pat we perform binary splits only when building a decision tree.\\n\\na) Is it possible to encounter pe “no features left” base case? Why?\\n\\nb) Is it possible to encounter pe “no examples left” base case? Why?\\n3. 3. What is pe main advantage of post-pruning over pre-pruning?\\n\\n© Alice Gao 2021 - v1.0 - Page 36 of 36', start_char_idx=None, end_char_idx=None, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n')]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "length of documents loaded: 1\n",
            "total number of document chunks generated :36\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:88: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "93a9fee5d80e463fa7ddd6dda91031c2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Fetching 5 files:   0%|          | 0/5 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0d9fe7612908447e952dda5dabcc1d12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/740 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b1e1b6f9d86446cc8cd29bf19a91a268",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.24k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b2718b8371614ef0a5b4f11af9cae152",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4ca879d912564375a96751eff46045c0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8560f18caa654018bc5f70c6c9154d1f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model_optimized.onnx:   0%|          | 0.00/218M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector DB created successfully !\n"
          ]
        }
      ],
      "source": [
        "vs,embed_model = create_vector_database()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2iQvi8LWN8Kn"
      },
      "outputs": [],
      "source": [
        "chat_model = ChatGroq(temperature=0.0,\n",
        "                      model_name=\"mixtral-8x7b-32768\",\n",
        "                      api_key=groq_api_key)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9gDJSnhdN8NW"
      },
      "outputs": [],
      "source": [
        "vectorstore = Chroma(embedding_function=embed_model,\n",
        "                      persist_directory=\"chroma_db_llamaparse1\",\n",
        "                      collection_name=\"rag\")\n",
        "\n",
        "retriever=vectorstore.as_retriever(search_kwargs={'k': 3})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OurzxS_KN8P-"
      },
      "outputs": [],
      "source": [
        "custom_prompt_template = \"\"\"Use the following pieces of information to answer questions of the user.\n",
        "\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "\n",
        "Only return the helpful content below and nothing else.\n",
        "Helpful answer:\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TQp-jDEFSZZd",
        "outputId": "7ca4c907-16fb-43e7-9aee-4e973996e165"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PromptTemplate(input_variables=['context', 'question'], template='Use the following pieces of information to answer questions of the user.\\n\\nContext: {context}\\nQuestion: {question}\\n\\nOnly return the helpful content below and nothing else.\\nHelpful answer:\\n')"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def set_custom_prompt():\n",
        "    \"\"\"\n",
        "    Prompt template for QA retrieval for each vectorstore\n",
        "    \"\"\"\n",
        "    prompt = PromptTemplate(template=custom_prompt_template,\n",
        "                            input_variables=['context', 'question'])\n",
        "    return prompt\n",
        "#\n",
        "prompt = set_custom_prompt()\n",
        "\n",
        "\n",
        "########################### RESPONSE ###########################\n",
        "PromptTemplate(input_variables=['context', 'question'], template=custom_prompt_template)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qL_-3tL9S5vR"
      },
      "outputs": [],
      "source": [
        "qa = RetrievalQA.from_chain_type(llm=chat_model,\n",
        "                               chain_type=\"stuff\",\n",
        "                               retriever=retriever,\n",
        "                               return_source_documents=True,\n",
        "                               chain_type_kwargs={\"prompt\": prompt})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pPTpbi7oTVuc"
      },
      "outputs": [],
      "source": [
        "response = qa.invoke({\n",
        "    \"query\": \"Generate 20 technical interview questions and answers suitable for a candidate with 0 year of experience \"\n",
        "             \"in the field, based on the provided content. Include a mix of basic, intermediate, tricky, and logical \"\n",
        "             \"questions. Follow a coherent order in the question formation. Provide the source documents \"\n",
        "})\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xGP1O0na3UF_"
      },
      "outputs": [],
      "source": [
        "temp_str=response['result']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VvZft5HvcxDe"
      },
      "outputs": [],
      "source": [
        "lines = temp_str.split(\"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SG9jnhQZczKm",
        "outputId": "d4dd8eec-7cff-4438-a011-248fb59c4d11"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Sure, here are 20 technical interview questions and answers based on the provided content:',\n",
              " '',\n",
              " '1. What is a decision tree and how does it correspond to a program?',\n",
              " 'Answer: A decision tree is a flowchart-like structure that is used to classify or predict a target variable based on input features. It corresponds to a program with a big nested if-then-else structure.',\n",
              " '2. What are the advantages of using a decision tree?',\n",
              " 'Answer: Decision trees are easy to understand, interpret, and visualize. They can handle both numerical and categorical data, and they can be used for both classification and regression tasks.',\n",
              " '3. What are the disadvantages of using a decision tree?',\n",
              " 'Answer: Decision trees can be prone to overfitting, especially if they are too deep. They can also be sensitive to small variations in the data, leading to different trees being generated for different training sets.',\n",
              " '4. What is decision tree learning algorithm?',\n",
              " 'Answer: Decision tree learning algorithm is a method for generating a decision tree from a dataset. It involves selecting the best feature to split the data at each node, recursively, until a stopping criterion is met.',\n",
              " '5. What are the issues in learning a decision tree?',\n",
              " 'Answer: The issues in learning a decision tree include deciding the order of testing the input features, and building a decision tree by splitting the examples whenever we test an input feature.',\n",
              " '6. What is the difference between a full decision tree and a pruned decision tree?',\n",
              " 'Answer: A full decision tree is a tree that is grown to its maximum size, while a pruned decision tree is a tree that has been reduced in size to avoid overfitting.',\n",
              " '7. What is the difference between a decision tree and a random forest?',\n",
              " 'Answer: A decision tree is a single tree, while a random forest is an ensemble of decision trees.',\n",
              " '8. What is the difference between a decision tree and a logistic regression?',\n",
              " 'Answer: A decision tree is a non-parametric model, while logistic regression is a parametric model.',\n",
              " '9. What is the difference between a decision tree and a support vector machine?',\n",
              " 'Answer: A decision tree is a white box model, while a support vector machine is a black box model.',\n",
              " '10. What is the difference between a decision tree and a neural network?',\n",
              " 'Answer: A decision tree is a rule-based model, while a neural network is a connectionist model.',\n",
              " '11. What is the difference between a decision tree and a naive Bayes classifier?',\n",
              " 'Answer: A decision tree is a probabilistic model, while a naive Bayes classifier is a Bayesian model.',\n",
              " '12. What is the difference between a decision tree and a k-nearest neighbor?',\n",
              " 'Answer: A decision tree is a lazy learner, while a k-nearest neighbor is an instance-based learner.',\n",
              " '13. What is the difference between a decision tree and a linear discriminant analysis?',\n",
              " 'Answer: A decision tree is a non-linear model, while a linear discriminant analysis is a linear model.',\n",
              " '14. What is the difference between a decision tree and a gradient boosting?',\n",
              " 'Answer: A decision tree is a weak learner, while a gradient boosting is a strong learner.',\n",
              " '15. What is the difference between a decision tree and an artificial neural network?',\n",
              " 'Answer: A decision tree is a symbolic approach, while an artificial neural network is a sub-symbolic approach.',\n",
              " '16. What is the difference between a decision tree and a fuzzy logic system?',\n",
              " 'Answer: A decision tree is a deterministic approach, while a fuzzy logic system is a non-deterministic approach.',\n",
              " '17. What is the difference between a decision tree and a genetic algorithm?',\n",
              " 'Answer: A decision tree is a supervised learning approach, while a genetic algorithm is an unsupervised learning approach.',\n",
              " '18. What is the difference between a decision tree and a reinforcement learning?',\n",
              " 'Answer: A decision tree is a batch learning approach, while a reinforcement learning is an online learning approach.',\n",
              " '19. What is the difference between a decision tree and a deep learning?',\n",
              " 'Answer: A decision tree is a shallow learning approach, while a deep learning is a deep learning approach.',\n",
              " '20. What is the difference between a decision tree and a natural language processing?',\n",
              " 'Answer: A decision tree is a structured learning approach, while a natural language processing is an unstructured learning approach.',\n",
              " '',\n",
              " 'Source documents:',\n",
              " '',\n",
              " '* Decision Tree Example: Which language should you learn?',\n",
              " '* Pet Selection Quiz',\n",
              " '* CS 486/686 Lecture 7',\n",
              " '* Decision Tree Learning Algorithm',\n",
              " '* Decision Tree Construction',\n",
              " '* Example Data for Tennis Prediction',\n",
              " '* Jeeves training set',\n",
              " '* Order of Testing Features']"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bv1II1G5d2Gv"
      },
      "outputs": [],
      "source": [
        "response2 = qa.invoke({\n",
        "    \"query\": \"Generate 20 technical interview questions and answers suitable for a candidate with 1 year of experience \"\n",
        "             \"in the field, based on the provided content. Include a mix of basic, intermediate, tricky, and logical \"\n",
        "             \"questions. Follow a coherent order in the question formation. \"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iVa_lmOs4Ma_",
        "outputId": "a2d944b2-c15d-464b-a928-3602d0bd4489"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Sure, here are 20 technical interview questions and answers based on the provided content:',\n",
              " '',\n",
              " '1. What is a decision tree and how is it used in machine learning?',\n",
              " 'Answer: A decision tree is a flowchart-like structure that is used to classify or predict examples in machine learning. Each internal node represents a feature, each branch represents a decision rule, and each leaf node represents an outcome.',\n",
              " '2. What is the decision tree learning algorithm?',\n",
              " 'Answer: The decision tree learning algorithm is a method for building a decision tree from a dataset. It involves selecting the best feature to split the data at each node, recursively, until a stopping criterion is met.',\n",
              " '3. What are some issues in learning a decision tree?',\n",
              " 'Answer: Some issues in learning a decision tree include overfitting, underfitting, noisy data, missing data, and irrelevant features.',\n",
              " '4. What is the order of testing features in the Jeeves data set?',\n",
              " 'Answer: The order of testing features in the Jeeves data set is Outlook, Temperature, Humidity, and Wind.',\n",
              " '5. How do you construct a decision tree for the Jeeves data set using the given order of testing features?',\n",
              " 'Answer: To construct a decision tree for the Jeeves data set using the given order of testing features, you start by testing Outlook. If Outlook is Sunny, you test Temperature. If Outlook is Rain, you test Wind. If there are multiple branches, you test Humidity before testing Wind.',\n",
              " '6. What is the difference between a decision tree and a program?',\n",
              " 'Answer: A decision tree is a graphical representation of a program with a big nested if-then-else structure.',\n",
              " '7. How do you convert a decision tree to a program?',\n",
              " 'Answer: To convert a decision tree to a program, you create a big nested if-then-else structure that corresponds to the decision tree.',\n",
              " '8. What is the purpose of the Decision Tree Construction section in the provided content?',\n",
              " 'Answer: The purpose of the Decision Tree Construction section in the provided content is to illustrate the process of constructing a decision tree for the Jeeves data set using the given order of testing features.',\n",
              " '9. What is the purpose of the Problem section in the provided content?',\n",
              " 'Answer: The purpose of the Problem section in the provided content is to state the problem of constructing a (full) decision tree for the Jeeves data set using the given order of testing features.',\n",
              " '10. What is the purpose of the Solution section in the provided content?',\n",
              " 'Answer: The purpose of the Solution section in the provided content is to provide a solution to the problem of constructing a (full) decision tree for the Jeeves data set using the given order of testing features.',\n",
              " '11. What is the purpose of the Decision Tree Example section in the provided content?',\n",
              " 'Answer: The purpose of the Decision Tree Example section in the provided content is to provide an example of a decision tree for a hypothetical problem.',\n",
              " '12. What is the purpose of the Pet Selection Quiz section in the provided content?',\n",
              " 'Answer: The purpose of the Pet Selection Quiz section in the provided content is to provide an example of a decision tree in the form of a quiz.',\n",
              " '13. What is the purpose of the Lecture 7 section in the provided content?',\n",
              " 'Answer: The purpose of the Lecture 7 section in the provided content is to provide an example of a decision tree for a hypothetical problem.',\n",
              " '14. What is the purpose of the Example Data for Tennis Prediction section in the provided content?',\n",
              " 'Answer: The purpose of the Example Data for Tennis Prediction section in the provided content is to provide an example of a dataset that can be used to build a decision tree.',\n",
              " '15. What is the purpose of the Should you use emoji in a conversation? section in the provided content?',\n",
              " 'Answer: The purpose of the Should you use emoji in a conversation? section in the provided content is to provide an example of a decision tree for a hypothetical problem.',\n",
              " '16. What is the purpose of the Lecture 7 section in the provided content?',\n",
              " 'Answer: The purpose of the Lecture 7 section in the provided content is to provide an example of a decision tree for a hypothetical problem.',\n",
              " '17. What is the purpose of the Decision Tree Learning Algorithm section in the provided content?',\n",
              " 'Answer: The purpose of the Decision Tree Learning Algorithm section in the provided content is to provide a high-level overview of the decision tree learning algorithm.',\n",
              " '18. What is the purpose of the 4.1 Issues in learning a decision tree section in the provided content?',\n",
              " 'Answer: The purpose of the 4.1 Issues in learning a decision tree section in the provided content is to highlight some of the challenges in building a decision tree from a dataset.']"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines2=response2['result'].split(\"\\n\")\n",
        "lines2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uw_zPjaC4T9Z"
      },
      "outputs": [],
      "source": [
        "response3 = qa.invoke({\n",
        "    \"query\": \"Generate 20 technical interview questions and answers suitable for a candidate with 5 year of experience \"\n",
        "             \"in the field, based on the provided content. Include a mix of basic, intermediate, tricky, and logical \"\n",
        "             \"questions. Follow a coherent order in the question formation. Do not add extra information by yourself\"\n",
        "})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXa8cHxlY5ks",
        "outputId": "485ff83f-9340-487c-cf5d-d6c86958844c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['Decision Tree Learning Questions:',\n",
              " '',\n",
              " '1. Q: What is a decision tree in machine learning?',\n",
              " '   A: A decision tree is a flowchart-like structure used for making decisions and predicting outcomes. Each internal node represents a feature or attribute, each branch represents a decision rule, and each leaf node represents an outcome.',\n",
              " '',\n",
              " '2. Q: What is the purpose of decision tree learning?',\n",
              " '   A: The goal of decision tree learning is to create a model that can predict the value of a target variable by learning simple decision rules inferred from the data features.',\n",
              " '',\n",
              " '3. Q: What are the key challenges in learning a decision tree?',\n",
              " '   A: Deciding the order of testing input features, handling missing values, and avoiding overfitting are some of the key challenges in learning a decision tree.',\n",
              " '',\n",
              " '4. Q: How does a decision tree correspond to a program?',\n",
              " '   A: A decision tree corresponds to a program with a big nested if-then-else structure, where each internal node represents a condition and each leaf node represents an outcome.',\n",
              " '',\n",
              " '5. Q: What is the process of constructing a decision tree?',\n",
              " '   A: The process involves selecting the best feature to split the data at each node, recursively applying the process to the resulting subsets, and stopping when a stopping criterion is met.',\n",
              " '',\n",
              " '6. Q: What are some common algorithms for decision tree learning?',\n",
              " '   A: ID3, C4.5, CART, and CHAID are some common algorithms for decision tree learning.',\n",
              " '',\n",
              " '7. Q: What is pruning in decision tree learning?',\n",
              " '   A: Pruning is a technique used to reduce the complexity of a decision tree by removing branches that do not contribute significantly to the accuracy of the model.',\n",
              " '',\n",
              " '8. Q: What is the difference between a categorical variable and a continuous variable in decision tree learning?',\n",
              " '   A: Categorical variables have a finite set of distinct values, while continuous variables can take on any value within a range.',\n",
              " '',\n",
              " '9. Q: How does decision tree learning handle missing values?',\n",
              " '   A: Decision tree learning can handle missing values by using various strategies, such as ignoring the example, using the most common value, or using a surrogate split.',\n",
              " '',\n",
              " '10. Q: What is the curse of dimensionality in decision tree learning?',\n",
              " '   A: The curse of dimensionality refers to the phenomenon where the number of possible decision trees grows exponentially with the number of features, making it difficult to find the optimal tree.',\n",
              " '',\n",
              " '11. Q: What is entropy in decision tree learning?',\n",
              " '   A: Entropy is a measure of the impurity or randomness of a set of examples. It is used in decision tree learning to determine the best feature to split the data.',\n",
              " '',\n",
              " '12. Q: What is information gain in decision tree learning?',\n",
              " '   A: Information gain is a measure of the reduction in entropy or impurity achieved by splitting the data based on a feature. It is used in decision tree learning to determine the best feature to split the data.',\n",
              " '',\n",
              " '13. Q: What is overfitting in decision tree learning?',\n",
              " '   A: Overfitting occurs when a decision tree is too complex and fits the training data too closely, resulting in poor generalization performance on new data.',\n",
              " '',\n",
              " '14. Q: What is cross-validation in decision tree learning?',\n",
              " '   A: Cross-validation is a technique used to evaluate the performance of a decision tree by dividing the data into training and testing sets and averaging the performance over multiple iterations.',\n",
              " '',\n",
              " '15. Q: What is a decision stump in decision tree learning?',\n",
              " '   A: A decision stump is a decision tree with a single internal node and two leaf nodes.',\n",
              " '',\n",
              " '16. Q: What is a random forest in decision tree learning?',\n",
              " '   A: A random forest is an ensemble of decision trees that are trained on different subsets of the data and combined to improve the accuracy and reduce the variance of the model.',\n",
              " '',\n",
              " '17. Q: What is boosting in decision tree learning?',\n",
              " '   A: Boosting is a technique used to improve the accuracy of a decision tree by iteratively reweighting the examples and training new trees to focus on the misclassified examples.',\n",
              " '',\n",
              " '18. Q: What is a Gini index in decision tree learning?',\n",
              " '   A: The Gini index is a measure of the impurity or randomness of a set of examples, similar to entropy. It is used in decision tree learning to determine the best feature to split the data.',\n",
              " '',\n",
              " '19. Q: What is a chi-square test in decision tree learning?',\n",
              " '   A: A chi-square test is a statistical test used in decision tree learning to determine the significance of the association between a feature and the target variable.',\n",
              " '',\n",
              " '20. Q: What is a cost-complexity pruning in decision tree learning?',\n",
              " '   A: Cost-complexity pruning is a technique used to prune a decision tree by minimizing the cost function that balances the complexity of the tree and the error rate.']"
            ]
          },
          "execution_count": 35,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines3=response3['result'].split(\"\\n\")\n",
        "lines3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IsmKVj9_Y8qj"
      },
      "outputs": [],
      "source": [
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HH1TudY2cvZB",
        "outputId": "b44d6e79-1261-4661-b525-f05ff2da681c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['When learning a decision tree, choosing a feature to test at each step by maximizing the expected information gain does not guarantee an optimal decision tree. This is because the approach is greedy and does not consider the future consequences of the current decision. It is possible that a suboptimal split at one step may lead to a better overall tree, but this is not guaranteed. Additionally, binary splits only further limit the possibilities of finding an optimal tree.']"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "lines4=response4['result'].split(\"\\n\")\n",
        "lines4"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4zxSSSbiczri"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "03b17b9d585b45cfa44bc06d1fd07158": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "082132fc225c46b08e559f1614af755c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ae548875b2649bb9dc994f02ef743b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0d9fe7612908447e952dda5dabcc1d12": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_50315b269dc044b58a3a64d8263b1778",
              "IPY_MODEL_ecf8f52d5f5e4da8b2a1ecea50d02f84",
              "IPY_MODEL_cd6e37718c9e4ba999d8fc9377d70a31"
            ],
            "layout": "IPY_MODEL_6c6e928c9687426faf5bc69f35b2a81f"
          }
        },
        "1485ee91a0d24ca5a5b5b4026801916d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "15509c24676441b6be900c19bd400c15": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e3b2ce1b1f484b1f9e62e90cc3740f23",
            "placeholder": "​",
            "style": "IPY_MODEL_82e75671196c4b809aa340a32bfbfe59",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "16b57400688d4cc6b06a60c27fb68949": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": "center",
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "flex",
            "flex": null,
            "flex_flow": "column",
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "50%"
          }
        },
        "1c16325ad8b94df1b776e07958c6795b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cc07a4a023784d7dbb5963967470836e",
            "placeholder": "​",
            "style": "IPY_MODEL_fa6a8d8c2a2843ababd4382b17f9f82c",
            "value": "\n<b>Thank You</b></center>"
          }
        },
        "1c540824311d413990a075f5dac79cbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1ec8416f6fb04a818238582ca0e5f6bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "217e549113a64c9984b357766a0ea142": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "VBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f5a9244cfaf246d6a5e88bac7a9c5d79"
            ],
            "layout": "IPY_MODEL_16b57400688d4cc6b06a60c27fb68949"
          }
        },
        "225966b82e484584a51107733526294f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2a0c560aa05a4cf986b36a8117a906a5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2d56cecd509142d1809414d902552d78": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "323cace826db45c38c755f5412f9bb1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a40e368a6364599951798abc32f0762",
            "max": 217824172,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_1c540824311d413990a075f5dac79cbc",
            "value": 217824172
          }
        },
        "3330173bbea5486182d6006d1565c914": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d71349a32e14e869a33246ac7ec10db",
            "placeholder": "​",
            "style": "IPY_MODEL_acf4804120ed40e2b01c14864196894e",
            "value": "Connecting..."
          }
        },
        "338f33ce9f7e4b3ba301bddea816584a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3499cc2930d6400d83175e729e7bd863": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3588c2718b204bd394353ffe02435976": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3fdd6f028102430a8dac1891e65cb7f4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "426de3c1bd5e43e093de4156003d0426": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "45a539ac3e094fa8a788950cbb8f2265": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "464a48743f2041ea83a0c8fbcf57d338": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "4ca879d912564375a96751eff46045c0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9282d14135a440baa634de1eae63bbfc",
              "IPY_MODEL_5c7cf9abcfde4fc29b6ef7f67f2d1528",
              "IPY_MODEL_5a65ce696fd94cc5a4b41b76ec0e3dcd"
            ],
            "layout": "IPY_MODEL_522c868fc1f543318fbc4f8fe51ae9d8"
          }
        },
        "4dfa9f22e06c4095932609f3a46a6d3f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e8f23577d4b4f7f8dc24b4e67bbee39": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "50315b269dc044b58a3a64d8263b1778": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_748b7688d8634a2cad3dbd7878c443d0",
            "placeholder": "​",
            "style": "IPY_MODEL_cbfc1e74f15047c5bd71caf817a70047",
            "value": "config.json: 100%"
          }
        },
        "522c868fc1f543318fbc4f8fe51ae9d8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "558e43ab7f07438dac7fcc25c83dc9d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3588c2718b204bd394353ffe02435976",
            "max": 1242,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2a0c560aa05a4cf986b36a8117a906a5",
            "value": 1242
          }
        },
        "5a65ce696fd94cc5a4b41b76ec0e3dcd": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f31f03da91004b3b879c60b02f9658fd",
            "placeholder": "​",
            "style": "IPY_MODEL_0ae548875b2649bb9dc994f02ef743b9",
            "value": " 711k/711k [00:00&lt;00:00, 6.73MB/s]"
          }
        },
        "5b6a8bf031814124b9b8de7b982b0aab": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c7cf9abcfde4fc29b6ef7f67f2d1528": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f8f8a8027e254cf987d508bacfa1b8fb",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_928873ab61b84fe8a8e4225ba4f99dbf",
            "value": 711396
          }
        },
        "6587127b35fe4d2282c564d35b877565": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4dfa9f22e06c4095932609f3a46a6d3f",
            "placeholder": "​",
            "style": "IPY_MODEL_338f33ce9f7e4b3ba301bddea816584a",
            "value": " 695/695 [00:00&lt;00:00, 6.60kB/s]"
          }
        },
        "66678d6523b8434b8212e4428a2f185d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c6e928c9687426faf5bc69f35b2a81f": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6cfca3acad0e473cbb68c9bb5431874c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "PasswordModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "PasswordModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "PasswordView",
            "continuous_update": true,
            "description": "Token:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_5b6a8bf031814124b9b8de7b982b0aab",
            "placeholder": "​",
            "style": "IPY_MODEL_e3ebd39e67e24143899db9957fddfceb",
            "value": ""
          }
        },
        "6edd2cc7b6ec437f8ec2024317cb09c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd636c9c779e4d10aa2d4ef409184eeb",
            "placeholder": "​",
            "style": "IPY_MODEL_426de3c1bd5e43e093de4156003d0426",
            "value": "<center> <img\nsrc=https://www.kaggle.com/static/images/site-logo.png\nalt='Kaggle'> <br> Create an API token from <a\nhref=\"https://www.kaggle.com/settings/account\" target=\"_blank\">your Kaggle\nsettings page</a> and paste it below along with your Kaggle username. <br> </center>"
          }
        },
        "73ff963bf61b499b904713e61984365c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "748b7688d8634a2cad3dbd7878c443d0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75acd162553044abb0ede44a93eb0980": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "78b98b90d9b8449b8253853a4d9fa2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7a40e368a6364599951798abc32f0762": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "802dd47a08eb46fea8afcc7638cfd182": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9f3148fbbe124f7eac5dd8bdf04f0591",
            "placeholder": "​",
            "style": "IPY_MODEL_3499cc2930d6400d83175e729e7bd863",
            "value": " 218M/218M [00:01&lt;00:00, 111MB/s]"
          }
        },
        "82e75671196c4b809aa340a32bfbfe59": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8560f18caa654018bc5f70c6c9154d1f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_88d043489bb744459ed1256f74935c3a",
              "IPY_MODEL_323cace826db45c38c755f5412f9bb1c",
              "IPY_MODEL_802dd47a08eb46fea8afcc7638cfd182"
            ],
            "layout": "IPY_MODEL_856e0b6bf1a648ea962234c31f8e0b7b"
          }
        },
        "856e0b6bf1a648ea962234c31f8e0b7b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88d043489bb744459ed1256f74935c3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d6251768a24c493f8c499de72acc5468",
            "placeholder": "​",
            "style": "IPY_MODEL_af89e3cc2b5c4408b562e2d1e5d559c6",
            "value": "model_optimized.onnx: 100%"
          }
        },
        "8cc7c8d4e08f4d44bd700b96b2e985ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8d71349a32e14e869a33246ac7ec10db": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9282d14135a440baa634de1eae63bbfc": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_da51a2dd1beb43ec873f9981d9abce70",
            "placeholder": "​",
            "style": "IPY_MODEL_4e8f23577d4b4f7f8dc24b4e67bbee39",
            "value": "tokenizer.json: 100%"
          }
        },
        "928873ab61b84fe8a8e4225ba4f99dbf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "93a9fee5d80e463fa7ddd6dda91031c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_c37d2e4629384eddaae629e5d32e9b61",
              "IPY_MODEL_dd14f2dbd6b14157afd08e46c0b7e7b2",
              "IPY_MODEL_98783ad5506b4c6e9da29f2f99146c44"
            ],
            "layout": "IPY_MODEL_e54772a611fe4ea1a59617d6b31138b9"
          }
        },
        "947dbb036e224114b5d45065caf6a485": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "TextModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextView",
            "continuous_update": true,
            "description": "Username:",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_f0c7c6a9025643809a6b55ee2a3fbe57",
            "placeholder": "​",
            "style": "IPY_MODEL_1485ee91a0d24ca5a5b5b4026801916d",
            "value": "kakuza"
          }
        },
        "98783ad5506b4c6e9da29f2f99146c44": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ecd4fee8e16b415fa3fa7e7aabcacfb7",
            "placeholder": "​",
            "style": "IPY_MODEL_f217b574934a475e85be163e57874477",
            "value": " 5/5 [00:02&lt;00:00,  1.38s/it]"
          }
        },
        "9e2ae7bf675f4edd9a6b0cf747ebf32a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9f3148fbbe124f7eac5dd8bdf04f0591": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "acf4804120ed40e2b01c14864196894e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "af89e3cc2b5c4408b562e2d1e5d559c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b1e1b6f9d86446cc8cd29bf19a91a268": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d97422a7031144edb60297f60012c993",
              "IPY_MODEL_558e43ab7f07438dac7fcc25c83dc9d4",
              "IPY_MODEL_c2918974b8fd4b72842cfb15d04db461"
            ],
            "layout": "IPY_MODEL_e006bdbc7f054f7a8cf98319f982efe4"
          }
        },
        "b2718b8371614ef0a5b4f11af9cae152": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_15509c24676441b6be900c19bd400c15",
              "IPY_MODEL_d7035b8868cb42339334f85acba121ad",
              "IPY_MODEL_6587127b35fe4d2282c564d35b877565"
            ],
            "layout": "IPY_MODEL_082132fc225c46b08e559f1614af755c"
          }
        },
        "c2918974b8fd4b72842cfb15d04db461": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f648cc320fe3498a909eed9c31d50220",
            "placeholder": "​",
            "style": "IPY_MODEL_2d56cecd509142d1809414d902552d78",
            "value": " 1.24k/1.24k [00:00&lt;00:00, 18.8kB/s]"
          }
        },
        "c37d2e4629384eddaae629e5d32e9b61": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3fdd6f028102430a8dac1891e65cb7f4",
            "placeholder": "​",
            "style": "IPY_MODEL_8cc7c8d4e08f4d44bd700b96b2e985ff",
            "value": "Fetching 5 files: 100%"
          }
        },
        "c9ba3dec115b476bb2c4ee06bae297fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ButtonModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Login",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_225966b82e484584a51107733526294f",
            "style": "IPY_MODEL_03b17b9d585b45cfa44bc06d1fd07158",
            "tooltip": ""
          }
        },
        "cbfc1e74f15047c5bd71caf817a70047": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cc07a4a023784d7dbb5963967470836e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd469d30dbcc4d0d9dce8b8ee93560c1": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd636c9c779e4d10aa2d4ef409184eeb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cd6e37718c9e4ba999d8fc9377d70a31": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d49d79be6aea44de9dd58fc7cdda8ca5",
            "placeholder": "​",
            "style": "IPY_MODEL_464a48743f2041ea83a0c8fbcf57d338",
            "value": " 740/740 [00:00&lt;00:00, 8.64kB/s]"
          }
        },
        "d49d79be6aea44de9dd58fc7cdda8ca5": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d6251768a24c493f8c499de72acc5468": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d7035b8868cb42339334f85acba121ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_66678d6523b8434b8212e4428a2f185d",
            "max": 695,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_78b98b90d9b8449b8253853a4d9fa2bc",
            "value": 695
          }
        },
        "d97422a7031144edb60297f60012c993": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_df91131b95724a72b96164c567e2f5c6",
            "placeholder": "​",
            "style": "IPY_MODEL_1ec8416f6fb04a818238582ca0e5f6bc",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "da51a2dd1beb43ec873f9981d9abce70": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "dd14f2dbd6b14157afd08e46c0b7e7b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73ff963bf61b499b904713e61984365c",
            "max": 5,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_75acd162553044abb0ede44a93eb0980",
            "value": 5
          }
        },
        "df91131b95724a72b96164c567e2f5c6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e006bdbc7f054f7a8cf98319f982efe4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3b2ce1b1f484b1f9e62e90cc3740f23": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e3ebd39e67e24143899db9957fddfceb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e4b42e47ce6e4026bd41e4960c666d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e54772a611fe4ea1a59617d6b31138b9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecd4fee8e16b415fa3fa7e7aabcacfb7": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ecf8f52d5f5e4da8b2a1ecea50d02f84": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cd469d30dbcc4d0d9dce8b8ee93560c1",
            "max": 740,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_45a539ac3e094fa8a788950cbb8f2265",
            "value": 740
          }
        },
        "f0c7c6a9025643809a6b55ee2a3fbe57": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f217b574934a475e85be163e57874477": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f31f03da91004b3b879c60b02f9658fd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f5a9244cfaf246d6a5e88bac7a9c5d79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "LabelModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e2ae7bf675f4edd9a6b0cf747ebf32a",
            "placeholder": "​",
            "style": "IPY_MODEL_e4b42e47ce6e4026bd41e4960c666d2c",
            "value": "Kaggle credentials successfully validated."
          }
        },
        "f648cc320fe3498a909eed9c31d50220": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f8f8a8027e254cf987d508bacfa1b8fb": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fa6a8d8c2a2843ababd4382b17f9f82c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
