{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ZAF059-Resume Screening Using Large Language Modelling\n",
        "**Developer Name:** SIVADHANDAPANI S\n",
        "\n",
        "\n",
        "**E-mail:** sivadhandapanis25@gmail.com"
      ],
      "metadata": {
        "id": "Aa5UIEVjVeiQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.Checking Python Version\n",
        "It is very helpfull for creating Container,venv or any config files while pushing to production"
      ],
      "metadata": {
        "id": "vZtMf8xPXH_D"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F90npzqlTcFk",
        "outputId": "87be7d68-1e65-4252-82b6-4159185b20db"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n"
          ]
        }
      ],
      "source": [
        "!python --version"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.Install neccessary libraries"
      ],
      "metadata": {
        "id": "2OitI4yXYL1d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pdf2image google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1sUsyxF47lED",
        "outputId": "d676fb4c-e62a-462b-8679-e784dc792d56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.10/dist-packages (0.5.2)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n",
            "Requirement already satisfied: google-ai-generativelanguage==0.6.2 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (0.6.2)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.11.1)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.84.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.27.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (3.20.3)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (2.7.1)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from google-generativeai) (4.11.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.10/dist-packages (from google-ai-generativelanguage==0.6.2->google-generativeai) (1.23.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.3.3)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.dev0,>=1.56.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.63.0)\n",
            "Requirement already satisfied: requests<3.0.0.dev0,>=2.18.0 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (2.31.0)\n",
            "Requirement already satisfied: httplib2<1dev,>=0.15.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (0.1.1)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic->google-generativeai) (2.18.2)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.62.2)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.10/dist-packages (from google-api-core->google-generativeai) (1.48.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.10/dist-packages (from httplib2<1dev,>=0.15.0->google-api-python-client->google-generativeai) (3.1.2)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0.dev0,>=2.18.0->google-api-core->google-generativeai) (2024.2.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3.Import  neccessary libraries"
      ],
      "metadata": {
        "id": "4mousv7sBSoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import base64\n",
        "import os\n",
        "import io\n",
        "from PIL import Image\n",
        "import pdf2image\n",
        "import google.generativeai as genai"
      ],
      "metadata": {
        "id": "3vjqLUbV7ebI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4.Define a Function to get a response from LLM\n",
        "\n",
        "Note-I use the Gemini Pro Version as LLM"
      ],
      "metadata": {
        "id": "vZM0cYrXBZma"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "genai.configure(api_key=\"AIzaSyCZuIdNXgKtK-7t-9AmhcLVIa7QUQE__jM\") #Replace your Gemini API\n",
        "\n",
        "def get_gemini_response(input,pdf_cotent,prompt):\n",
        "    model=genai.GenerativeModel('gemini-pro-vision')\n",
        "    response=model.generate_content([input,pdf_content[0],prompt])\n",
        "    return response.text"
      ],
      "metadata": {
        "id": "zY_YvM8s70Uc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#  5.Define a Function to convert a PDF to input for Gemini Model\n",
        "\n",
        "**Function Explaination:**\n",
        "\n",
        "1. **Argument**:\n",
        "   - `uploaded_file_path`: This is the path to the uploaded PDF file.\n",
        "\n",
        "2. **Check if file path is provided**:\n",
        "   - The function checks if the `uploaded_file_path` is not `None`. If it is, it proceeds with processing the PDF file. Otherwise, it raises a `FileNotFoundError` indicating that no file was uploaded.\n",
        "\n",
        "3. **PDF to Image Conversion**:\n",
        "   - The function uses `pdf2image.convert_from_path()` function to convert the PDF file into a list of PIL (Python Imaging Library) images.\n",
        "\n",
        "4. **Extract First Page**:\n",
        "   - It selects the first page from the list of images generated from the PDF.\n",
        "\n",
        "5. **Convert Image to Bytes**:\n",
        "   - It converts the first page image into a byte array using `io.BytesIO()` and `save()` methods. This byte array represents the image in memory.\n",
        "\n",
        "6. **Encode Image as Base64**:\n",
        "   - The byte array representing the image is then encoded into a base64 string using `base64.b64encode()` method. This is done to facilitate easy transmission of image data.\n",
        "\n",
        "7. **Construct Metadata**:\n",
        "   - It constructs a dictionary containing metadata about the image, including its MIME type (`image/jpeg`) and the base64 encoded image data.\n",
        "\n",
        "8. **Return Output**:\n",
        "   - The function returns a list containing this dictionary, representing the image data in a format that can be easily transmitted or processed further.\n"
      ],
      "metadata": {
        "id": "bfE5tYTFBvSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def input_pdf_setup(uploaded_file_path):\n",
        "    if uploaded_file_path is not None:\n",
        "        ## Convert the PDF to image\n",
        "        images=pdf2image.convert_from_path(uploaded_file_path)\n",
        "        # Replace convert_from_file if you pass file as input (for web based application)\n",
        "        # Eg:\n",
        "        #images=pdf2image.convert_from_file(file_obj.read())\n",
        "        first_page=images[0]\n",
        "\n",
        "        # Convert to bytes\n",
        "        img_byte_arr = io.BytesIO()\n",
        "        first_page.save(img_byte_arr, format='JPEG')\n",
        "        img_byte_arr = img_byte_arr.getvalue()\n",
        "\n",
        "        pdf_parts = [\n",
        "            {\n",
        "                \"mime_type\": \"image/jpeg\",\n",
        "                \"data\": base64.b64encode(img_byte_arr).decode()  # encode to base64\n",
        "            }\n",
        "        ]\n",
        "        return pdf_parts\n",
        "    else:\n",
        "        raise FileNotFoundError(\"No file uploaded\")"
      ],
      "metadata": {
        "id": "OJJF8fni73U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6.Installing Poppler and add it to Path Variable for pdf2image[Error Handling]"
      ],
      "metadata": {
        "id": "x-i1APhWCEbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!apt-get install poppler-utils libpoppler-cpp-dev\n",
        "!pip install -v -v python-poppler\n",
        "!pip install pdf2image"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WXSViyFrDbJi",
        "outputId": "73e9bcc2-d301-429b-f3ae-4d25aded037e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  libpoppler-cpp0v5\n",
            "The following NEW packages will be installed:\n",
            "  libpoppler-cpp-dev libpoppler-cpp0v5 poppler-utils\n",
            "0 upgraded, 3 newly installed, 0 to remove and 45 not upgraded.\n",
            "Need to get 236 kB of archives.\n",
            "After this operation, 928 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-cpp0v5 amd64 22.02.0-2ubuntu0.3 [38.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 libpoppler-cpp-dev amd64 22.02.0-2ubuntu0.3 [11.7 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 poppler-utils amd64 22.02.0-2ubuntu0.3 [186 kB]\n",
            "Fetched 236 kB in 2s (99.8 kB/s)\n",
            "Selecting previously unselected package libpoppler-cpp0v5:amd64.\n",
            "(Reading database ... 121920 files and directories currently installed.)\n",
            "Preparing to unpack .../libpoppler-cpp0v5_22.02.0-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libpoppler-cpp0v5:amd64 (22.02.0-2ubuntu0.3) ...\n",
            "Selecting previously unselected package libpoppler-cpp-dev:amd64.\n",
            "Preparing to unpack .../libpoppler-cpp-dev_22.02.0-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking libpoppler-cpp-dev:amd64 (22.02.0-2ubuntu0.3) ...\n",
            "Selecting previously unselected package poppler-utils.\n",
            "Preparing to unpack .../poppler-utils_22.02.0-2ubuntu0.3_amd64.deb ...\n",
            "Unpacking poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Setting up poppler-utils (22.02.0-2ubuntu0.3) ...\n",
            "Setting up libpoppler-cpp0v5:amd64 (22.02.0-2ubuntu0.3) ...\n",
            "Setting up libpoppler-cpp-dev:amd64 (22.02.0-2ubuntu0.3) ...\n",
            "Processing triggers for man-db (2.10.2-1) ...\n",
            "Processing triggers for libc-bin (2.35-0ubuntu3.4) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_5.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbb.so.12 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind_2_0.so.3 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc_proxy.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbmalloc.so.2 is not a symbolic link\n",
            "\n",
            "/sbin/ldconfig.real: /usr/local/lib/libtbbbind.so.3 is not a symbolic link\n",
            "\n",
            "Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "Non-user install because site-packages writeable\n",
            "Created temporary directory: /tmp/pip-build-tracker-10r1jhai\n",
            "Initialized build tracking at /tmp/pip-build-tracker-10r1jhai\n",
            "Created build tracker: /tmp/pip-build-tracker-10r1jhai\n",
            "Entered build tracker: /tmp/pip-build-tracker-10r1jhai\n",
            "Created temporary directory: /tmp/pip-install-vdhgkmp2\n",
            "Created temporary directory: /tmp/pip-ephem-wheel-cache-txn80uz8\n",
            "1 location(s) to search for versions of python-poppler:\n",
            "* https://pypi.org/simple/python-poppler/\n",
            "Fetching project page and analyzing links: https://pypi.org/simple/python-poppler/\n",
            "Getting page https://pypi.org/simple/python-poppler/\n",
            "Found index url https://pypi.org/simple/\n",
            "Looking up \"https://pypi.org/simple/python-poppler/\" in the cache\n",
            "Request header has \"max_age\" as 0, cache bypassed\n",
            "Starting new HTTPS connection (1): pypi.org:443\n",
            "https://pypi.org:443 \"GET /simple/python-poppler/ HTTP/1.1\" 200 1286\n",
            "Updating cache with response from \"https://pypi.org/simple/python-poppler/\"\n",
            "etag object cached for 1209600 seconds\n",
            "Caching due to etag\n",
            "Fetched page https://pypi.org/simple/python-poppler/ as application/vnd.pypi.simple.v1+json\n",
            "  Found link https://files.pythonhosted.org/packages/7b/c7/929827ce08a057c7948df9c925e7f0c9b011bf37a110648a6399ec07d912/python-poppler-0.1.0.tar.gz (from https://pypi.org/simple/python-poppler/) (requires-python:>=3.7), version: 0.1.0\n",
            "  Found link https://files.pythonhosted.org/packages/48/f0/e7f408e68ca2d4a8325b2f3a6c62d30e0e8b3a6319b5a2169ef14baef09d/python-poppler-0.1.1.tar.gz (from https://pypi.org/simple/python-poppler/) (requires-python:>=3.7), version: 0.1.1\n",
            "  Found link https://files.pythonhosted.org/packages/06/fa/705faf4ee1c43952c1d1ac9d93efc9493a5283fbfad5c6b9b82359798d88/python-poppler-0.1.2.tar.gz (from https://pypi.org/simple/python-poppler/) (requires-python:>=3.7), version: 0.1.2\n",
            "  Found link https://files.pythonhosted.org/packages/01/e2/eabad063ec3e60d917afb776951c295d944d2f238633f19150339577b657/python-poppler-0.2.0.tar.gz (from https://pypi.org/simple/python-poppler/) (requires-python:>=3.7), version: 0.2.0\n",
            "  Found link https://files.pythonhosted.org/packages/83/b4/d48c0596a923a6cd06aebc6dc5380b0afb1413f49d9086cc6245e3098a4f/python-poppler-0.2.1.tar.gz (from https://pypi.org/simple/python-poppler/) (requires-python:>=3.7), version: 0.2.1\n",
            "  Found link https://files.pythonhosted.org/packages/38/77/8f7b5c8ff2c0a7c3afbb3dc8d2342ef2e3ef48053a467e02913e18b73dc6/python-poppler-0.2.2.tar.gz (from https://pypi.org/simple/python-poppler/) (requires-python:>=3.6), version: 0.2.2\n",
            "  Found link https://files.pythonhosted.org/packages/c6/9a/e02dfd4f27865c60de305ead36c79f2c619093fa82836436f76fe8da5247/python-poppler-0.3.0.tar.gz (from https://pypi.org/simple/python-poppler/) (requires-python:>=3.6), version: 0.3.0\n",
            "  Found link https://files.pythonhosted.org/packages/ef/02/8589c3eefdb73a5229a446e557551fa1bbc168e52ea5e334b87c307024c0/python_poppler-0.4.0.tar.gz (from https://pypi.org/simple/python-poppler/) (requires-python:>=3.6), version: 0.4.0\n",
            "  Found link https://files.pythonhosted.org/packages/15/ff/e9c8f176c376223146d212771016595b4ad8d0a83d40636b7b39798a7219/python_poppler-0.4.1.tar.gz (from https://pypi.org/simple/python-poppler/) (requires-python:>=3.6), version: 0.4.1\n",
            "Skipping link: not a file: https://pypi.org/simple/python-poppler/\n",
            "Given no hashes to check 9 links for project 'python-poppler': discarding no candidates\n",
            "Collecting python-poppler\n",
            "  Created temporary directory: /tmp/pip-unpack-p6sifsvw\n",
            "  Looking up \"https://files.pythonhosted.org/packages/15/ff/e9c8f176c376223146d212771016595b4ad8d0a83d40636b7b39798a7219/python_poppler-0.4.1.tar.gz\" in the cache\n",
            "  No cache entry available\n",
            "  Starting new HTTPS connection (1): files.pythonhosted.org:443\n",
            "  https://files.pythonhosted.org:443 \"GET /packages/15/ff/e9c8f176c376223146d212771016595b4ad8d0a83d40636b7b39798a7219/python_poppler-0.4.1.tar.gz HTTP/1.1\" 200 138527\n",
            "  Downloading python_poppler-0.4.1.tar.gz (138 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/138.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m  Ignoring unknown cache-control directive: immutable\n",
            "  Updating cache with response from \"https://files.pythonhosted.org/packages/15/ff/e9c8f176c376223146d212771016595b4ad8d0a83d40636b7b39798a7219/python_poppler-0.4.1.tar.gz\"\n",
            "  etag object cached for 1209600 seconds\n",
            "  Caching due to etag\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Added python-poppler from https://files.pythonhosted.org/packages/15/ff/e9c8f176c376223146d212771016595b4ad8d0a83d40636b7b39798a7219/python_poppler-0.4.1.tar.gz to build tracker '/tmp/pip-build-tracker-10r1jhai'\n",
            "  Created temporary directory: /tmp/pip-build-env-_bzjw9df\n",
            "  Running command pip subprocess to install build dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting meson-python\n",
            "    Downloading meson_python-0.16.0-py3-none-any.whl (26 kB)\n",
            "  Collecting meson>=1.0.0\n",
            "    Downloading meson-1.4.0-py3-none-any.whl (935 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 935.5/935.5 kB 27.5 MB/s eta 0:00:00\n",
            "  Collecting wheel\n",
            "    Using cached wheel-0.43.0-py3-none-any.whl (65 kB)\n",
            "  Collecting packaging>=19.0 (from meson-python)\n",
            "    Downloading packaging-24.0-py3-none-any.whl (53 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 53.5/53.5 kB 7.3 MB/s eta 0:00:00\n",
            "  Collecting pyproject-metadata>=0.7.1 (from meson-python)\n",
            "    Downloading pyproject_metadata-0.8.0-py3-none-any.whl (7.5 kB)\n",
            "  Collecting tomli>=1.0.0 (from meson-python)\n",
            "    Downloading tomli-2.0.1-py3-none-any.whl (12 kB)\n",
            "  Installing collected packages: wheel, tomli, packaging, meson, pyproject-metadata, meson-python\n",
            "    Creating /tmp/pip-build-env-_bzjw9df/overlay/local/bin\n",
            "    changing mode of /tmp/pip-build-env-_bzjw9df/overlay/local/bin/wheel to 755\n",
            "    changing mode of /tmp/pip-build-env-_bzjw9df/overlay/local/bin/meson to 755\n",
            "  Successfully installed meson-1.4.0 meson-python-0.16.0 packaging-24.0 pyproject-metadata-0.8.0 tomli-2.0.1 wheel-0.43.0\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command Getting requirements to build wheel\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Running command pip subprocess to install backend dependencies\n",
            "  Using pip 23.1.2 from /usr/local/lib/python3.10/dist-packages/pip (python 3.10)\n",
            "  Collecting ninja>=1.8.2\n",
            "    Downloading ninja-1.11.1.1-py2.py3-none-manylinux1_x86_64.manylinux_2_5_x86_64.whl (307 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 307.2/307.2 kB 7.3 MB/s eta 0:00:00\n",
            "  Collecting patchelf>=0.11.0\n",
            "    Downloading patchelf-0.17.2.1-py2.py3-none-manylinux_2_5_x86_64.manylinux1_x86_64.musllinux_1_1_x86_64.whl (425 kB)\n",
            "       ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 425.7/425.7 kB 34.1 MB/s eta 0:00:00\n",
            "  Installing collected packages: patchelf, ninja\n",
            "    changing mode of /tmp/pip-build-env-_bzjw9df/normal/local/bin/ninja to 755\n",
            "  Successfully installed ninja-1.11.1.1 patchelf-0.17.2.1\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Created temporary directory: /tmp/pip-modern-metadata-0gqq651x\n",
            "  Running command Preparing metadata (pyproject.toml)\n",
            "  + meson setup /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys -Dbuildtype=release -Db_ndebug=if-release -Db_vscrt=md --native-file=/tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/meson-python-native-file.ini\n",
            "  The Meson build system\n",
            "  Version: 1.4.0\n",
            "  Source dir: /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b\n",
            "  Build dir: /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys\n",
            "  Build type: native build\n",
            "  Project name: python-poppler\n",
            "  Project version: 0.4.1\n",
            "  C++ compiler for the host machine: c++ (gcc 11.4.0 \"c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\")\n",
            "  C++ linker for the host machine: c++ ld.bfd 2.38\n",
            "  Host machine cpu family: x86_64\n",
            "  Host machine cpu: x86_64\n",
            "  Found pkg-config: YES (/usr/bin/pkg-config) 0.29.2\n",
            "  Run-time dependency poppler-cpp found: YES 22.02.0\n",
            "  Program python3 found: YES (/usr/bin/python3)\n",
            "  Downloading pybind11 source from https://github.com/pybind/pybind11/archive/refs/tags/v2.10.3.tar.gz\n",
            "  Downloading pybind11 patch from https://wrapdb.mesonbuild.com/v2/pybind11_2.10.3-1/get_patch\n",
            "\n",
            "  Executing subproject pybind11\n",
            "\n",
            "  pybind11| Project name: pybind11\n",
            "  pybind11| Project version: 2.10.3\n",
            "  pybind11| C++ compiler for the host machine: c++ (gcc 11.4.0 \"c++ (Ubuntu 11.4.0-1ubuntu1~22.04) 11.4.0\")\n",
            "  pybind11| C++ linker for the host machine: c++ ld.bfd 2.38\n",
            "  pybind11| Build targets in project: 0\n",
            "  pybind11| Subproject pybind11 finished.\n",
            "\n",
            "  Configuring _version.py using configuration\n",
            "  Run-time dependency python found: YES 3.10\n",
            "  Build targets in project: 13\n",
            "\n",
            "  python-poppler 0.4.1\n",
            "\n",
            "    Subprojects\n",
            "      pybind11    : YES\n",
            "\n",
            "    User defined options\n",
            "      Native files: /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/meson-python-native-file.ini\n",
            "      buildtype   : release\n",
            "      b_ndebug    : if-release\n",
            "      b_vscrt     : md\n",
            "\n",
            "  Found ninja-1.11.1.git.kitware.jobserver-1 at /tmp/pip-build-env-_bzjw9df/normal/local/bin/ninja\n",
            "  + /tmp/pip-build-env-_bzjw9df/normal/local/bin/ninja\n",
            "  [1/26] Compiling C++ object src/cpp/destination.cpython-310-x86_64-linux-gnu.so.p/destination.cpp.o\n",
            "  [2/26] Linking target src/cpp/destination.cpython-310-x86_64-linux-gnu.so\n",
            "  [3/26] Compiling C++ object src/cpp/global_.cpython-310-x86_64-linux-gnu.so.p/global.cpp.o\n",
            "  [4/26] Linking target src/cpp/global_.cpython-310-x86_64-linux-gnu.so\n",
            "  [5/26] Compiling C++ object src/cpp/document.cpython-310-x86_64-linux-gnu.so.p/document.cpp.o\n",
            "  [6/26] Linking target src/cpp/document.cpython-310-x86_64-linux-gnu.so\n",
            "  [7/26] Compiling C++ object src/cpp/embedded_file.cpython-310-x86_64-linux-gnu.so.p/embedded_file.cpp.o\n",
            "  [8/26] Linking target src/cpp/embedded_file.cpython-310-x86_64-linux-gnu.so\n",
            "  [9/26] Compiling C++ object src/cpp/font.cpython-310-x86_64-linux-gnu.so.p/font.cpp.o\n",
            "  [10/26] Linking target src/cpp/font.cpython-310-x86_64-linux-gnu.so\n",
            "  [11/26] Compiling C++ object src/cpp/global.cpython-310-x86_64-linux-gnu.so.p/global.cpp.o\n",
            "  [12/26] Linking target src/cpp/global.cpython-310-x86_64-linux-gnu.so\n",
            "  [13/26] Compiling C++ object src/cpp/image.cpython-310-x86_64-linux-gnu.so.p/image.cpp.o\n",
            "  ../src/cpp/image.cpp: In function ‘void poppler::set_data(poppler::image&, char*)’:\n",
            "  ../src/cpp/image.cpp:32:11: warning: variable ‘img_data’ set but not used [-Wunused-but-set-variable]\n",
            "     32 |     char *img_data = img.data();\n",
            "        |           ^~~~~~~~\n",
            "  [14/26] Linking target src/cpp/image.cpython-310-x86_64-linux-gnu.so\n",
            "  [15/26] Compiling C++ object src/cpp/page_renderer.cpython-310-x86_64-linux-gnu.so.p/page_renderer.cpp.o\n",
            "  [16/26] Linking target src/cpp/page_renderer.cpython-310-x86_64-linux-gnu.so\n",
            "  [17/26] Compiling C++ object src/cpp/page_transition.cpython-310-x86_64-linux-gnu.so.p/page_transition.cpp.o\n",
            "  [18/26] Linking target src/cpp/page_transition.cpython-310-x86_64-linux-gnu.so\n",
            "  [19/26] Compiling C++ object src/cpp/rectangle.cpython-310-x86_64-linux-gnu.so.p/rectangle.cpp.o\n",
            "  [20/26] Linking target src/cpp/rectangle.cpython-310-x86_64-linux-gnu.so\n",
            "  [21/26] Compiling C++ object src/cpp/page.cpython-310-x86_64-linux-gnu.so.p/page.cpp.o\n",
            "  [22/26] Linking target src/cpp/page.cpython-310-x86_64-linux-gnu.so\n",
            "  [23/26] Compiling C++ object src/cpp/toc.cpython-310-x86_64-linux-gnu.so.p/toc.cpp.o\n",
            "  [24/26] Linking target src/cpp/toc.cpython-310-x86_64-linux-gnu.so\n",
            "  [25/26] Compiling C++ object src/cpp/version.cpython-310-x86_64-linux-gnu.so.p/version.cpp.o\n",
            "  [26/26] Linking target src/cpp/version.cpython-310-x86_64-linux-gnu.so\n",
            "  [1/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/global_.cpython-310-x86_64-linux-gnu.so\n",
            "  [2/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/destination.cpython-310-x86_64-linux-gnu.so\n",
            "  [3/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/document.cpython-310-x86_64-linux-gnu.so\n",
            "  [4/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/embedded_file.cpython-310-x86_64-linux-gnu.so\n",
            "  [5/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/font.cpython-310-x86_64-linux-gnu.so\n",
            "  [6/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/global.cpython-310-x86_64-linux-gnu.so\n",
            "  [7/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/image.cpython-310-x86_64-linux-gnu.so\n",
            "  [8/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/page_renderer.cpython-310-x86_64-linux-gnu.so\n",
            "  [9/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/page_transition.cpython-310-x86_64-linux-gnu.so\n",
            "  [10/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/page.cpython-310-x86_64-linux-gnu.so\n",
            "  [11/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/rectangle.cpython-310-x86_64-linux-gnu.so\n",
            "  [12/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/toc.cpython-310-x86_64-linux-gnu.so\n",
            "  [13/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/cpp/version.cpython-310-x86_64-linux-gnu.so\n",
            "  [14/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/__init__.py\n",
            "  [15/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/destination.py\n",
            "  [16/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/document.py\n",
            "  [17/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/embeddedfile.py\n",
            "  [18/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/font.py\n",
            "  [19/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/image.py\n",
            "  [20/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/page.py\n",
            "  [21/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/pagerenderer.py\n",
            "  [22/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/pagetransition.py\n",
            "  [23/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/rectangle.py\n",
            "  [24/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/toc.py\n",
            "  [25/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/utilities.py\n",
            "  [26/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/.mesonpy-uhu3f8ys/src/poppler/_version.py\n",
            "  [27/27] /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b/src/poppler/cpp/__init__.py\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Source in /tmp/pip-install-vdhgkmp2/python-poppler_239f972f52ec45afb0d83f3ad336413b has version 0.4.1, which satisfies requirement python-poppler from https://files.pythonhosted.org/packages/15/ff/e9c8f176c376223146d212771016595b4ad8d0a83d40636b7b39798a7219/python_poppler-0.4.1.tar.gz\n",
            "  Removed python-poppler from https://files.pythonhosted.org/packages/15/ff/e9c8f176c376223146d212771016595b4ad8d0a83d40636b7b39798a7219/python_poppler-0.4.1.tar.gz from build tracker '/tmp/pip-build-tracker-10r1jhai'\n",
            "Created temporary directory: /tmp/pip-unpack-jvnn37e2\n",
            "Building wheels for collected packages: python-poppler\n",
            "  Created temporary directory: /tmp/pip-wheel-xynucr9o\n",
            "  Destination directory: /tmp/pip-wheel-xynucr9o\n",
            "  Running command Building wheel for python-poppler (pyproject.toml)\n",
            "  Building wheel for python-poppler (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-poppler: filename=python_poppler-0.4.1-cp310-cp310-linux_x86_64.whl size=1226010 sha256=8ce851da700ab31dcebb72d9efd24fc6c21eb9056f1460e9f2df869a7bc322f6\n",
            "  Stored in directory: /root/.cache/pip/wheels/86/b6/50/1ffef302ce48f582ed01759e3d43ffd609822f1bdd9266aeea\n",
            "Successfully built python-poppler\n",
            "Installing collected packages: python-poppler\n",
            "\n",
            "Successfully installed python-poppler-0.4.1\n",
            "Removed build tracker: '/tmp/pip-build-tracker-10r1jhai'\n",
            "Requirement already satisfied: pdf2image in /usr/local/lib/python3.10/dist-packages (1.17.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.10/dist-packages (from pdf2image) (9.4.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Sample Job Description:**\n",
        "**Job Title: Junior Data Scientist**\n",
        "\n",
        "**Job Description:**\n",
        "\n",
        "Are you passionate about data and its potential to drive insights and innovation? We are seeking a motivated and analytical Junior Data Scientist to join our dynamic team. As a Junior Data Scientist, you will work alongside experienced professionals to contribute to various data science projects aimed at solving real-world problems and enhancing business performance.\n",
        "\n",
        "**Key Responsibilities:**\n",
        "\n",
        "1. **Data Collection and Preparation:** Assist in gathering and cleaning data from various sources, ensuring its accuracy and reliability for analysis.\n",
        "\n",
        "2. **Exploratory Data Analysis (EDA):** Conduct preliminary analysis to understand the structure and patterns within the data, identifying potential trends and outliers.\n",
        "\n",
        "3. **Statistical Analysis:** Apply basic statistical techniques to interpret data and derive meaningful insights.\n",
        "\n",
        "4. **Machine Learning Modeling:** Collaborate with senior team members to develop and implement machine learning models for predictive analysis, classification, and clustering tasks.\n",
        "\n",
        "5. **Model Evaluation and Validation:** Evaluate model performance using appropriate metrics and techniques, and validate model results to ensure reliability and generalization.\n",
        "\n",
        "6. **Data Visualization:** Create visualizations to effectively communicate findings and insights to stakeholders using tools like matplotlib, seaborn, or Tableau.\n",
        "\n",
        "7. **Documentation:** Maintain thorough documentation of data science processes, methodologies, and results to facilitate knowledge sharing and reproducibility.\n",
        "\n",
        "**Requirements:**\n",
        "\n",
        "- Bachelor’s degree in Computer Science, Statistics, Mathematics, or related field.\n",
        "- Proficiency in programming languages such as Python or R.\n",
        "- Familiarity with data manipulation libraries like pandas and numpy.\n",
        "- Basic understanding of machine learning algorithms and techniques.\n",
        "- Strong analytical and problem-solving skills.\n",
        "- Excellent communication and teamwork abilities.\n",
        "\n",
        "**Preferred Qualifications:**\n",
        "\n",
        "- Experience with data visualization tools such as matplotlib, seaborn, or Tableau.\n",
        "- Knowledge of SQL for data manipulation and extraction.\n",
        "- Previous internship or project experience in data science or related field.\n",
        "\n",
        "**Benefits:**\n",
        "\n",
        "- Competitive salary and benefits package.\n",
        "- Opportunities for career growth and professional development.\n",
        "- Collaborative and inclusive work environment.\n",
        "- Exposure to cutting-edge technologies and methodologies in data science.\n",
        "- Chance to make a real impact by contributing to meaningful projects that drive business success.\n",
        "\n",
        "Join us in harnessing the power of data to unlock new insights and drive innovation! Apply now to kick-start your career in data science."
      ],
      "metadata": {
        "id": "WNXRSO2MAzCr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7.Testing the LLM model with Sample data"
      ],
      "metadata": {
        "id": "u98B00eECcDm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_prompt= \"\"\"\n",
        "You are an skilled ATS (Applicant Tracking System) scanner with a deep understanding of all technologies and ATS functionality,\n",
        "your task is to evaluate the resume against the provided job description. give me the percentage of match if the resume matches\n",
        "the job description. First the output should come as percentage and then keywords missing and last final thoughts.\n",
        "\"\"\"\n",
        "job_description='''\n",
        "Job Title: Junior Data Scientist\n",
        "\n",
        "Job Description:\n",
        "\n",
        "Are you passionate about data and its potential to drive insights and innovation? We are seeking a motivated and analytical Junior Data Scientist to join our dynamic team. As a Junior Data Scientist, you will work alongside experienced professionals to contribute to various data science projects aimed at solving real-world problems and enhancing business performance.\n",
        "\n",
        "Key Responsibilities:\n",
        "\n",
        "Data Collection and Preparation: Assist in gathering and cleaning data from various sources, ensuring its accuracy and reliability for analysis.\n",
        "\n",
        "Exploratory Data Analysis (EDA): Conduct preliminary analysis to understand the structure and patterns within the data, identifying potential trends and outliers.\n",
        "\n",
        "Statistical Analysis: Apply basic statistical techniques to interpret data and derive meaningful insights.\n",
        "\n",
        "Machine Learning Modeling: Collaborate with senior team members to develop and implement machine learning models for predictive analysis, classification, and clustering tasks.\n",
        "\n",
        "Model Evaluation and Validation: Evaluate model performance using appropriate metrics and techniques, and validate model results to ensure reliability and generalization.\n",
        "\n",
        "Data Visualization: Create visualizations to effectively communicate findings and insights to stakeholders using tools like matplotlib, seaborn, or Tableau.\n",
        "\n",
        "Documentation: Maintain thorough documentation of data science processes, methodologies, and results to facilitate knowledge sharing and reproducibility.\n",
        "\n",
        "Requirements:\n",
        "\n",
        "Bachelor’s degree in Computer Science, Statistics, Mathematics, or related field.\n",
        "Proficiency in programming languages such as Python or R.\n",
        "Familiarity with data manipulation libraries like pandas and numpy.\n",
        "Basic understanding of machine learning algorithms and techniques.\n",
        "Strong analytical and problem-solving skills.\n",
        "Excellent communication and teamwork abilities.\n",
        "Preferred Qualifications:\n",
        "\n",
        "Experience with data visualization tools such as matplotlib, seaborn, or Tableau.\n",
        "Knowledge of SQL for data manipulation and extraction.\n",
        "Previous internship or project experience in data science or related field.\n",
        "Benefits:\n",
        "\n",
        "Competitive salary and benefits package.\n",
        "Opportunities for career growth and professional development.\n",
        "Collaborative and inclusive work environment.\n",
        "Exposure to cutting-edge technologies and methodologies in data science.\n",
        "Chance to make a real impact by contributing to meaningful projects that drive business success.\n",
        "Join us in harnessing the power of data to unlock new insights and drive innovation! Apply now to kick-start your career in data science.\n",
        "'''\n",
        "resume1=\"/content/Sivadhandapani_S_DS_Resume.pdf\" #Replace Resume path\n",
        "if resume is not None:\n",
        "  pdf_content=input_pdf_setup(uploaded_file_path=resume1)\n",
        "  response=get_gemini_response(input_prompt,pdf_content,job_description)\n",
        "  print(\"The Repsonse is:\")\n",
        "  print(response)\n",
        "else:\n",
        "  print(\"Please uplaod the resume\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "jn8mC4E-_Wdr",
        "outputId": "835102ea-725f-4dc3-8985-29e4b5d03b33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Repsonse is:\n",
            " Percentage Match: 75%\n",
            "\n",
            "Keywords Missing: NLP, Natural Language Processing, Deep Learning, Computer Vision, SQL, NoSQL, Hadoop, Spark, Hive, Pig, TensorFlow, PyTorch, Keras, scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, Tableau, Power BI, QlikView, Data Mining, Data Warehousing, Data Integration, Data Governance, Data Security, Data Privacy, Data Ethics, Cloud Computing, AWS, Azure, Google Cloud Platform, Big Data, Artificial Intelligence, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Autonomous Vehicles, Internet of Things, Blockchain, Augmented Reality, Virtual Reality, Mixed Reality, Extended Reality, 5G, Edge Computing, Quantum Computing, Cybersecurity, Information Security, Risk Management, Compliance, Governance, Audit, Controls, Data Protection, Privacy, Incident Response, Disaster Recovery, Business Continuity, Information Technology, IT Service Management, ITIL, DevOps, Agile, Scrum, Kanban, Lean, Six Sigma, Continuous Improvement, Quality Assurance, Testing, Automation, Performance Testing, Load Testing, Stress Testing, Security Testing, Penetration Testing, Vulnerability Assessment, Risk Assessment, Threat Modeling, Data Classification, Data Leakage Prevention, Data Loss Prevention, Data Encryption, Data Masking, Data Anonymization, Data Pseudonymization, Data Tokenization, Data Sanitization, Data Destruction, Data Archival, Data Backup, Data Recovery, Data Migration, Data Integration, Data Warehousing, Data Mining, Business Intelligence, Reporting, Analytics, Dashboards, Visualization, Data Visualization, Data Storytelling, Data Journalism, Data Science, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Autonomous Vehicles, Internet of Things, Blockchain, Augmented Reality, Virtual Reality, Mixed Reality, Extended Reality, 5G, Edge Computing, Quantum Computing, Cybersecurity, Information Security, Risk Management, Compliance, Governance, Audit, Controls, Data Protection, Privacy, Incident Response, Disaster Recovery, Business Continuity, Information Technology, IT Service Management, ITIL, DevOps, Agile, Scrum, Kanban, Lean, Six Sigma, Continuous Improvement, Quality Assurance, Testing, Automation, Performance Testing, Load Testing, Stress Testing, Security Testing, Penetration Testing, Vulnerability Assessment, Risk Assessment, Threat Modeling, Data Classification, Data Leakage Prevention, Data Loss Prevention, Data Encryption, Data Masking, Data Anonymization, Data Pseudonymization, Data Tokenization, Data Sanitization, Data Destruction, Data Archival, Data Backup, Data Recovery, Data Migration, Data Integration, Data Warehousing, Data Mining, Business Intelligence, Reporting, Analytics, Dashboards, Visualization, Data Visualization, Data Storytelling, Data Journalism\n",
            "\n",
            "Final Thoughts: The candidate's skills and experience are a good match for the job description. However, the candidate does not have experience with some of the specific technologies listed in the job description, such as NLP, Natural Language Processing, Deep Learning, Computer Vision, SQL, NoSQL, Hadoop, Spark, Hive, Pig, TensorFlow, PyTorch, Keras, scikit-learn, Pandas, NumPy, Matplotlib, Seaborn, Tableau, Power BI, QlikView, Data Mining, Data Warehousing, Data Integration, Data Governance, Data Security, Data Privacy, Data Ethics, Cloud Computing, AWS, Azure, Google Cloud Platform, Big Data, Artificial Intelligence, Machine Learning, Deep Learning, Natural Language Processing, Computer Vision, Robotics, Autonomous Vehicles, Internet of Things, Blockchain, Augmented Reality, Virtual Reality, Mixed Reality, Extended Reality, 5G, Edge Computing, Quantum Computing, Cybersecurity, Information Security, Risk Management, Compliance, Governance, Audit, Controls, Data Protection, Privacy, Incident Response, Disaster Recovery, Business Continuity, Information Technology, IT Service Management, ITIL, DevOps, Agile, Scrum, Kanban, Lean, Six Sigma, Continuous Improvement, Quality Assurance, Testing, Automation, Performance Testing, Load Testing, Stress Testing, Security Testing, Penetration Testing, Vulnerability Assessment, Risk Assessment, Threat Modeling, Data Classification, Data Leakage Prevention, Data Loss Prevention, Data Encryption, Data Masking, Data Anonymization, Data Pseudonymization, Data Tokenization, Data Sanitization, Data Destruction, Data Archival, Data Backup, Data Recovery, Data Migration, Data Integration, Data Warehousing, Data Mining, Business Intelligence, Reporting, Analytics, Dashboards, Visualization, Data Visualization, Data Storytelling, Data Journalism.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resume2=\"/content/web-developer-resume-example.pdf\" #Replace Resume path\n",
        "if resume is not None:\n",
        "  pdf_content=input_pdf_setup(uploaded_file_path=resume2)\n",
        "  response=get_gemini_response(input_prompt,pdf_content,job_description)\n",
        "  print(\"The Repsonse is:\")\n",
        "  print(response)\n",
        "else:\n",
        "  print(\"Please uplaod the resume\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        },
        "id": "P3n2OR3g5MBn",
        "outputId": "4524fea7-121c-42db-9e51-3c8de56aaa7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Repsonse is:\n",
            " Percentage Match: 40%\n",
            "\n",
            "Keywords Missing: Python, R, pandas, numpy, machine learning algorithms, SQL, data visualization tools\n",
            "\n",
            "Final Thoughts: The candidate has a background in computer science and has taken some relevant coursework, but their skills and experience do not closely align with the job description.\n"
          ]
        }
      ]
    }
  ]
}